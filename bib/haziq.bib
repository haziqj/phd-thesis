@book{ramsay2005functional,
  title={Functional Data Analysis},
  author={James Ramsay and B. W. Silverman},
  year={2005},
  publisher={Springer}
}


@article{wassermann2006all,
  title={All of nonparametric statistics},
  author={Wassermann, Larry},
  journal={New York},
  year={2006}
}

@book{kokoszka2017introduction,
  title={Introduction to functional data analysis},
  author={Kokoszka, Piotr and Reimherr, Matthew},
  year={2017},
  publisher={CRC Press}
}

@inproceedings{lloyd2015variational,
  title={Variational inference for Gaussian process modulated Poisson processes},
  author={Lloyd, Chris and Gunter, Tom and Osborne, Michael and Roberts, Stephen},
  booktitle={International Conference on Machine Learning},
  pages={1814--1822},
  year={2015}
}

@article{casella2009consistency,
  title={Consistency of Bayesian procedures for variable selection},
  author={Casella, George and Gir{\'o}n, F Javier and Mart{\'\i}nez, M Lina and Moreno, Elias},
  journal={The Annals of Statistics},
  pages={1207--1228},
  year={2009},
  publisher={JSTOR}
}

@article{bickel2013asymptotic,
  title={Asymptotic normality of maximum likelihood and its variational approximation for stochastic blockmodels},
  author={Bickel, Peter and Choi, David and Chang, Xiangyu and Zhang, Hai},
  journal={The Annals of Statistics},
  pages={1922--1943},
  year={2013},
  publisher={JSTOR}
}

@article{hall2011asymptotic,
  title={Asymptotic normality and valid inference for Gaussian variational approximation},
  author={Hall, Peter and Pham, Tung and Wand, Matt P and Wang, Shen SJ and others},
  journal={The Annals of Statistics},
  volume={39},
  number={5},
  pages={2502--2532},
  year={2011},
  publisher={Institute of Mathematical Statistics}
}

@article{zhang2012regularized,
  title={Regularized learning in Banach spaces as an optimization problem: representer theorems},
  author={Zhang, Haizhang and Zhang, Jun},
  journal={Journal of Global Optimization},
  volume={54},
  number={2},
  pages={235--250},
  year={2012},
  publisher={Springer}
}

@article{zhang2009reproducing,
  title={Reproducing kernel Banach spaces for machine learning},
  author={Zhang, Haizhang and Xu, Yuesheng and Zhang, Jun},
  journal={Journal of Machine Learning Research},
  volume={10},
  number={Dec},
  pages={2741--2775},
  year={2009}
}

@article{sriperumbudur2013density,
  title={Density estimation in infinite dimensional exponential families},
  author={Sriperumbudur, Bharath and Fukumizu, Kenji and Gretton, Arthur and Hyv{\"a}rinen, Aapo and Kumar, Revant},
  journal={arXiv preprint arXiv:1312.3516},
  year={2013}
}

@article{ormerod2017variational,
  title={A variational Bayes approach to variable selection},
  author={Ormerod, John T and You, Chong and M{\"u}ller, Samuel and others},
  journal={Electronic Journal of Statistics},
  volume={11},
  number={2},
  pages={3549--3594},
  year={2017},
  publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}

@article{lee2003gene,
  title={Gene selection: a Bayesian variable selection approach},
  author={Lee, Kyeong Eun and Sha, Naijun and Dougherty, Edward R and Vannucci, Marina and Mallick, Bani K},
  journal={Bioinformatics},
  volume={19},
  number={1},
  pages={90--97},
  year={2003},
  publisher={Oxford University Press}
}

@article{hoeting1999bayesian,
  title={Bayesian model averaging: a tutorial},
  author={Hoeting, Jennifer A and Madigan, David and Raftery, Adrian E and Volinsky, Chris T},
  journal={Statistical science},
  pages={382--401},
  year={1999},
  publisher={JSTOR}
}

@article{kyung2010penalized,
  title={Penalized regression, standard errors, and Bayesian lassos},
  author={Kyung, Minjung and Gill, Jeff and Ghosh, Malay and Casella, George and others},
  journal={Bayesian Analysis},
  volume={5},
  number={2},
  pages={369--411},
  year={2010},
  publisher={International Society for Bayesian Analysis}
}

@article{zou2005regularization,
  title={Regularization and variable selection via the elastic net},
  author={Zou, Hui and Hastie, Trevor},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={67},
  number={2},
  pages={301--320},
  year={2005},
  publisher={Wiley Online Library}
}

@article{hoerl1970ridge,
  title={Ridge regression: Biased estimation for nonorthogonal problems},
  author={Hoerl, Arthur E and Kennard, Robert W},
  journal={Technometrics},
  volume={12},
  number={1},
  pages={55--67},
  year={1970},
  publisher={Taylor \& Francis Group}
}

@article{schwarz1978estimating,
  title={Estimating the dimension of a model},
  author={Schwarz, Gideon and others},
  journal={The annals of statistics},
  volume={6},
  number={2},
  pages={461--464},
  year={1978},
  publisher={Institute of Mathematical Statistics}
}

@incollection{akaike1973,
  title={Information theory and an extension of the maximum likelihood principle},
  author={Akaike, Hirotogu},
  booktitle={2nd International Symposium on Information Theory},
  pages={267--281},
  year={1973},
  publisher={Akadémiai Kiadó}
}

@article{mallows1973some,
  title={Some comments on C p},
  author={Mallows, Colin L},
  journal={Technometrics},
  volume={15},
  number={4},
  pages={661--675},
  year={1973},
  publisher={Taylor \& Francis Group}
}

@book{miller2002subset,
  title={Subset selection in regression},
  author={Miller, Alan},
  year={2002},
  publisher={CRC Press}
}

@article{breslow1993approximate,
  title={Approximate inference in generalized linear mixed models},
  author={Breslow, Norman E and Clayton, David G},
  journal={Journal of the American statistical Association},
  volume={88},
  number={421},
  pages={9--25},
  year={1993},
  publisher={Taylor \& Francis Group}
}

@article{jordan1999introduction,
  title={An introduction to variational methods for graphical models},
  author={Jordan, Michael I and Ghahramani, Zoubin and Jaakkola, Tommi S and Saul, Lawrence K},
  journal={Machine learning},
  volume={37},
  number={2},
  pages={183--233},
  year={1999},
  publisher={Springer}
}

@article{wei1990monte,
  title={A Monte Carlo implementation of the EM algorithm and the poor man's data augmentation algorithms},
  author={Wei, Greg CG and Tanner, Martin A},
  journal={Journal of the American statistical Association},
  volume={85},
  number={411},
  pages={699--704},
  year={1990},
  publisher={Taylor \& Francis}
}

@book{mclachlan2007algorithm,
  title={The EM algorithm and extensions},
  author={McLachlan, Geoffrey and Krishnan, Thriyambakam},
  volume={382},
  year={2007},
  publisher={John Wiley \& Sons}
}

@book{davison2003statistical,
  title={Statistical models},
  author={Davison, Anthony Christopher},
  volume={11},
  year={2003},
  publisher={Cambridge University Press}
}

@article{casella1985introduction,
  title={An introduction to empirical Bayes data analysis},
  author={Casella, George},
  journal={The American Statistician},
  volume={39},
  number={2},
  pages={83--87},
  year={1985},
  publisher={Taylor \& Francis}
}

@incollection{robbins1985jerzy,
  title={Jerzy Neyman Memorial Lecture Some Thoughts on Empirical Bayes Estimation},
  author={Robbins, Herbert},
  booktitle={Herbert Robbins Selected Papers},
  pages={87--97},
  year={1985},
  publisher={Springer}
}

@techreport{robbins1956empirical,
  title={An empirical Bayes approach to statistics},
  author={Robbins, Herbert},
  year={1956},
  institution={COLUMBIA UNIVERSITY New York City United States}
}

@book{berger2013statistical,
  title={Statistical decision theory and Bayesian analysis},
  author={Berger, James O},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@book{robert2007bayesian,
  title={The Bayesian choice: from decision-theoretic foundations to computational implementation},
  author={Robert, Christian},
  year={2007},
  publisher={Springer Science \& Business Media}
}

@book{kadane2011principles,
  title={Principles of uncertainty},
  author={Kadane, Joseph B},
  year={2011},
  publisher={CRC Press}
}

@article{berger2006case,
  title={The case for objective Bayesian analysis},
  author={Berger, James and others},
  journal={Bayesian analysis},
  volume={1},
  number={3},
  pages={385--402},
  year={2006}
}

@article{hajivassiliou1998method,
  title={The method of simulated scores for the estimation of LDV models},
  author={Hajivassiliou, Vassilis A and McFadden, Daniel L},
  journal={Econometrica},
  pages={863--896},
  year={1998},
  publisher={JSTOR}
}

@article{keane1994solution,
  title={The solution and estimation of discrete choice dynamic programming models by simulation and interpolation: Monte Carlo evidence},
  author={Keane, Michael P and Wolpin, Kenneth I},
  journal={the Review of economics and statistics},
  pages={648--672},
  year={1994},
  publisher={JSTOR}
}

@article{hajivassiliou1996simulation,
  title={Simulation of multivariate normal rectangle probabilities and their derivatives theoretical and computational results},
  author={Hajivassiliou, Vassilis and McFadden, Daniel and Ruud, Paul},
  journal={Journal of econometrics},
  volume={72},
  number={1-2},
  pages={85--134},
  year={1996},
  publisher={Elsevier}
}

@article{chen2017use,
  title={On the use of bootstrap with variational inference: Theory, interpretation, and a two-sample test example},
  author={Chen, Yen-Chi and Wang, Y Samuel and Erosheva, Elena A},
  journal={arXiv preprint arXiv:1711.11057},
  year={2017}
}

@article{dansie1985parameter,
  title={Parameter estimability in the multinomial probit model},
  author={Dansie, BR},
  journal={Transportation Research Part B: Methodological},
  volume={19},
  number={6},
  pages={526--528},
  year={1985},
  publisher={Elsevier}
}

@article{bunch1991estimability,
  title={Estimability in the multinomial probit model},
  author={Bunch, David S},
  journal={Transportation Research Part B: Methodological},
  volume={25},
  number={1},
  pages={1--12},
  year={1991},
  publisher={Elsevier}
}

@article{hofmann2008kernel,
  title={Kernel methods in machine learning},
  author={Hofmann, Thomas and Sch{\"o}lkopf, Bernhard and Smola, Alexander J},
  journal={The annals of statistics},
  pages={1171--1220},
  year={2008},
  publisher={JSTOR}
}

@article{madigan1994model,
  title={Model selection and accounting for model uncertainty in graphical models using Occam's window},
  author={Madigan, David and Raftery, Adrian E},
  journal={Journal of the American Statistical Association},
  volume={89},
  number={428},
  pages={1535--1546},
  year={1994},
  publisher={Taylor \& Francis}
}

@article{scott2014predicting,
  title={Predicting the present with bayesian structural time series},
  author={Scott, Steven L and Varian, Hal R},
  journal={International Journal of Mathematical Modelling and Numerical Optimisation},
  volume={5},
  number={1-2},
  pages={4--23},
  year={2014},
  publisher={Inderscience Publishers Ltd}
}

@article{Breiman1985,
author = {Breiman, L and Friedman, J H},
file = {:Users/haziqjamil/Documents/Mendeley Desktop/Breiman, Friedman/Journal of the American Statistical Association/Breiman, Friedman - 1985 - Estimating optimal transformations for multiple-regression and correlation.pdf:pdf},
journal = {Journal of the American Statistical Association},
keywords = {smoothing},
number = {391},
pages = {614--619},
title = {{Estimating optimal transformations for multiple-regression and correlation}},
volume = {80},
year = {1985}
}

@article{Casella2006,
abstract = {A novel fully automatic Bayesian procedure for variable selection in normal regression models is proposed. The procedure uses the posterior probabilities of the models to drive a stochastic search. The posterior probabilities are computed using intrinsic priors, which can be considered default priors for model selection problems; that is, they are derived from the model structure and are free from tuning parameters. Thus they can be seen as objective priors for variable selection. The stochastic search is based on a Metropolis–Hastings algorithm with a stationary distribution proportional to the model posterior probabilities. The procedure is illustrated on both simulated and real examples.},
author = {Casella, George and Moreno, El{\'{i}}as},
doi = {10.1198/016214505000000646},
file = {:Users/haziqjamil/Documents/Mendeley Desktop/Casella, Moreno/Journal of the American Statistical Association/Casella, Moreno - 2006 - Objective Bayesian Variable Selection.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {hastings algorithm,intrinsic prior,methods,metropolis,monte carlo markov chain,normal linear regression},
number = {473},
pages = {157--167},
title = {{Objective Bayesian Variable Selection}},
volume = {101},
year = {2006}
}

@article{McDonald1973,
author = {McDonald, Gary C and Schwing, Richard C},
journal = {Technometrics},
number = {3},
pages = {463--481},
publisher = {Taylor & Francis},
title = {{Instabilities of regression estimates relating air pollution to mortality}},
volume = {15},
year = {1973}
}

@article{George1993,
author = {George, Edward I and McCulloch, Robert E},
file = {:Users/haziqjamil/Documents/Mendeley Desktop/George, McCulloch/Journal of the American Statistical Association/George, McCulloch - 1993 - Variable Selection Via Gibbs Sampling.pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {423},
pages = {881--889},
title = {{Variable Selection Via Gibbs Sampling}},
url = {http://www.jstor.org/stable/2290777?seq=1#page_scan_tab_contents},
volume = {88},
year = {1993}
}

@article{dellaportas2002bayesian,
  title={On Bayesian model and variable selection using MCMC},
  author={Dellaportas, Petros and Forster, Jonathan J and Ntzoufras, Ioannis},
  journal={Statistics and Computing},
  volume={12},
  number={1},
  pages={27--36},
  year={2002},
  publisher={Springer}
}

@book{Ntzoufras2008,
author = {Ntzoufras, Ioannis},
booktitle = {Wiley},
doi = {10.1002/9780470434567.ch11},
file = {:Users/haziqjamil/Documents/Mendeley Desktop/Ntzoufras/Wiley/Ntzoufras - 2011 - Bayesian Modeling Using WinBUGS.pdf:pdf},
keywords = {Bayes factors,Monte Carlo estimators,harmonic mean estimators,marginal likelihood,prior predictive distributions},
pages = {389--433},
publisher = {Wiley},
title = {{Bayesian Modeling Using WinBUGS}},
year = {2011}
}

@article{Fouskakis2008,
abstract = {Traditional variable-selection strategies in generalized linear models (GLMs) seek to optimize a measure of predictive accuracy without regard for the cost of data collection. When the purpose of such model building is the creation of predictive scales to be used in future studies with constrained budgets, the standard approach may not be optimal. We propose a Bayesian decision-theoretic framework for variable selection in binary-outcome GLMs where the budget for data collection is constrained and potential predictors may vary considerably in cost. The method is illustrated using data from a large study of quality of hospital care in the U.S. in the 1980s. Especially when the number of available predictors p is large, it is important to use an appropriate technique for optimization (e.g., in an application presented here where p = 83, the space over which we search has 283 .= 1025 elements, which is too large to explore using brute force enumeration). Specifically, we investigate simulated annealing (SA), genetic algorithms (GAs), and the tabu search (TS) method used in operations research, and we develop a context-specific version of SA, improved simulated annealing (ISA), that performs better than its generic counterpart. When p was modest in our study, we found that GAs performed relatively poorly for all but the very best user-defined input configurations, generic SA did not perform well, and TS had excellent median performance and was much less sensitive to suboptimal choice of user-defined inputs. When p was large in our study, the best versions of GA and ISA outperformed TS and generic SA. Our results are presented in the context of health policy but can apply to other quality assessment settings with dichotomous outcomes as well.},
author = {Fouskakis, Dimitris and Draper, David},
doi = {10.1198/016214508000001048},
file = {:Users/haziqjamil/Downloads/016214508000001048.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {annealing,bayesian decision theory,cross-validation,genetic algorithm,input,logistic regression,maximization,monte carlo methods,of expected utility,output analysis,prediction,quality of health care,sickness at hospital admission,simulated,tabu search,variable selection},
number = {484},
pages = {1367--1381},
title = {{Comparing Stochastic Optimization Methods for Variable Selection in Binary Outcome Prediction, With Application to Health Policy}},
volume = {103},
year = {2008}
}

@article{Barbieri2004,
abstract = {Often the goal of model selection is to choose a model for future prediction, and it is natural to measure the accuracy of a future prediction by squared error loss. Under the Bayesian approach, it is commonly perceived that the optimal predictive model is the model with highest posterior probability, but this is not necessarily the case. In this paper we show that, for selection among normal linear models, the optimal predictive model is often the median probability model, which is defined as the model consisting of those variables which have overall posterior probability greater than or equal to 1/2 of being in a model. The median probability model often differs from the highest probability model.},
archivePrefix = {arXiv},
arxivId = {arXiv:math/0406464v1},
author = {Barbieri, Maria Maddalena and Berger, James O},
doi = {10.1214/009053604000000238},
eprint = {0406464v1},
file = {:Users/haziqjamil/Downloads/euclid.aos.1085408489.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Bayesian linear models,Predictive distribution,Squared error loss,Variable selection},
number = {3},
pages = {870--897},
primaryClass = {arXiv:math},
title = {{Optimal predictive model selection}},
volume = {32},
year = {2004}
}

@article{geweke1996variable,
  title={Variable selection and model comparison in regression},
  author={Geweke, John},
  journal={In Bayesian Statistics 5},
  year={1996}
}

@article{mitchell1988bayesian,
  title={Bayesian variable selection in linear regression},
  author={Mitchell, Toby J and Beauchamp, John J},
  journal={Journal of the American Statistical Association},
  volume={83},
  number={404},
  pages={1023--1032},
  year={1988},
  publisher={Taylor \& Francis}
}

@article{raftery1997bayesian,
  title={Bayesian model averaging for linear regression models},
  author={Raftery, Adrian E and Madigan, David and Hoeting, Jennifer A},
  journal={Journal of the American Statistical Association},
  volume={92},
  number={437},
  pages={179--191},
  year={1997},
  publisher={Taylor \& Francis}
}

@article{OHara2009,
author = {O'Hara, R B and Sillanp{\"{a}}{\"{a}}, M J},
doi = {10.1214/09-BA403},
file = {:Users/haziqjamil/Documents/Mendeley Desktop/O'Hara, Sillanp{\"{a}}{\"{a}}/Bayesian Analysis/O'Hara, Sillanp{\"{a}}{\"{a}} - 2009 - A review of Bayesian variable selection methods what, how and which.pdf:pdf},
issn = {1936-0975},
journal = {Bayesian Analysis},
keywords = {bugs,mcmc,variable selection},
number = {1},
pages = {85--117},
title = {{A review of Bayesian variable selection methods: what, how and which}},
url = {http://projecteuclid.org/euclid.ba/1340370391},
volume = {4},
year = {2009}
}

@article{Chipman2001,
author = {Chipman, Hugh and George, Edward I and McCulloch, Robert E},
file = {:Users/haziqjamil/Documents/Mendeley Desktop/Chipman, George, McCulloch/IMS Lecture Notes - Monograph Series/Chipman, George, McCulloch - 2001 - The Practical Implementation of Bayesian Model Selection.pdf:pdf},
journal = {IMS Lecture Notes - Monograph Series},
pages = {65--134},
title = {{The Practical Implementation of Bayesian Model Selection}},
volume = {38},
year = {2001}
}

@article{Kuo1998,
author = {Kuo, L and Mallick, B},
file = {:Users/haziqjamil/Documents/Mendeley Desktop/Kuo, Mallick/Sankhya The Indian Journal of Statistics, Series B/Kuo, Mallick - 1998 - Variable selection for regression models.pdf:pdf},
journal = {Sankhya: The Indian Journal of Statistics, Series B},
number = {1},
pages = {65--81},
title = {{Variable selection for regression models}},
volume = {60},
year = {1998}
}

@book{SAS2008,
address = {Cary, NC},
author = {{SAS Institute Inc.}},
edition = {2nd},
isbn = {978-1-60764-566-5},
publisher = {SAS Institute Inc.},
title = {{SAS/STAT(R) 9.2 User's Guide}},
url = {https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_reg_sect055.htm},
year = {2008}
}

@article{park2008bayesian,
  title={The bayesian lasso},
  author={Park, Trevor and Casella, George},
  journal={Journal of the American Statistical Association},
  volume={103},
  number={482},
  pages={681--686},
  year={2008},
  publisher={Taylor \& Francis}
}

@article{tibshirani1996regression,
  title={Regression shrinkage and selection via the lasso},
  author={Tibshirani, Robert},
  journal={Journal of the Royal Statistical Society. Series B (Methodological)},
  pages={267--288},
  year={1996},
  publisher={JSTOR}
}

@article{fernandez2001benchmark,
  title={Benchmark priors for Bayesian model averaging},
  author={Fernandez, Carmen and Ley, Eduardo and Steel, Mark FJ},
  journal={Journal of Econometrics},
  volume={100},
  number={2},
  pages={381--427},
  year={2001},
  publisher={Elsevier}
}

@article{liang2008mixtures,
  title={Mixtures of g priors for Bayesian variable selection},
  author={Liang, Feng and Paulo, Rui and Molina, German and Clyde, Merlise A and Berger, Jim O},
  journal={Journal of the American Statistical Association},
  volume={103},
  number={481},
  pages={410--423},
  year={2008},
  publisher={Taylor \& Francis}
}

@phdthesis{deterding1989speaker,
  title={Speaker normalization for automatic speech recognition},
  author={Deterding, David Henry},
  school={University of Cambridge},
  year={1989}
}

@phdthesis{robinson1989dynamic,
  title={Dynamic error propagation networks},
  author={Robinson, Anthony John},
  year={1989},
  school={University of Cambridge}
}

@article{kuss2005assessing,
  title={Assessing approximate inference for binary Gaussian process classification},
  author={Kuss, Malte and Rasmussen, Carl Edward},
  journal={Journal of machine learning research},
  volume={6},
  number={Oct},
  pages={1679--1704},
  year={2005}
}

@article{taylor2013lgcp,
  title={lgcp: an R package for inference with spatial and spatio-temporal log-Gaussian Cox processes},
  author={Taylor, Benjamin M and Davies, Tilman M and Rowlingson, Barry S and Diggle, Peter J and others},
  journal={Journal of Statistical Software},
  volume={52},
  number={4},
  pages={1--40},
  year={2013},
  publisher={Foundation for Open Access Statistics}
}

@article{diggle2013spatial,
  title={Spatial and spatio-temporal log-Gaussian Cox processes: extending the geostatistical paradigm},
  author={Diggle, Peter J and Moraga, Paula and Rowlingson, Barry and Taylor, Benjamin M},
  journal={Statistical Science},
  pages={542--563},
  year={2013},
  publisher={JSTOR}
}

@article{diggle2005nonparametric,
  title={Nonparametric estimation of spatial segregation in a multivariate point process: bovine tuberculosis in Cornwall, UK},
  author={Diggle, Peter and Zheng, Pingping and Durr, Peter},
  journal={Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  volume={54},
  number={3},
  pages={645--658},
  year={2005},
  publisher={Wiley Online Library}
}

@book{friedman2001elements,
  title={The elements of statistical learning},
  author={Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
  volume={1},
  year={2001},
  publisher={Springer series in statistics New York}
}

@article{agresti2000tutorial,
  title={Tutorial in biostatistics: Strategies comparing treatment on binary response with multi-centre data},
  author={Agresti, Alan and Hartzel, Jonathan},
  journal={Statistics in medicine},
  volume={19},
  pages={1115--1139},
  year={2000}
}

@BOOK{skrondal2012multilevel,
title = {Multilevel and Longitudinal Modeling Using Stata, 3rd Edition},
author = {Rabe-Hesketh, Sophia and Skrondal, Anders},
year = {2012},
edition = {3rd},
publisher = {StataCorp LP},
abstract = {This text is a Stata-specific treatment of generalized linear mixed models, also known as multilevel or hierarchical models. These models are "mixed" in the sense that they allow fixed and random effects and are "generalized" in the sense that they are appropriate not only for continuous Gaussian responses but also for binary, count, and other types of limited dependent variables.},
keywords = {Stata; generalized linear mixed model; multilevel model; hierarchical model; fixed effects; random effects},
url = {https://EconPapers.repec.org/RePEc:tsj:spbook:mimus2}
}

@book{skrondal2004generalized,
  title={Generalized latent variable modeling: Multilevel, longitudinal, and structural equation models},
  author={Skrondal, Anders and Rabe-Hesketh, Sophia},
  year={2004},
  publisher={Crc Press}
}

@article{breiman2001random,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={45},
  number={1},
  pages={5--32},
  year={2001},
  publisher={Springer}
}

@article{tibshirani2002diagnosis,
  title={Diagnosis of multiple cancer types by shrunken centroids of gene expression},
  author={Tibshirani, Robert and Hastie, Trevor and Narasimhan, Balasubramanian and Chu, Gilbert},
  journal={Proceedings of the National Academy of Sciences},
  volume={99},
  number={10},
  pages={6567--6572},
  year={2002},
  publisher={National Acad Sciences}
}

@inproceedings{guvenir1997supervised,
  title={A supervised machine learning algorithm for arrhythmia analysis},
  author={Guvenir, H Altay and Acar, Burak and Demiroz, Gulsen and Cekin, Ayhan},
  booktitle={Computers in Cardiology 1997},
  pages={433--436},
  year={1997},
  organization={IEEE}
}

@article{cannings2017random,
  title={Random-projection ensemble classification},
  author={Cannings, Timothy I and Samworth, Richard J},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology) with discussion},
  volume={79},
  number={4},
  pages={959--1035},
  year={2017},
  publisher={Wiley Online Library}
}

@article{chan1997maximum,
  title={Maximum likelihood estimation for probit-linear mixed models with correlated random effects},
  author={Chan, Jennifer SK and Kuk, Anthony YC},
  journal={Biometrics},
  pages={86--97},
  year={1997},
  publisher={JSTOR}
}

@article{butler1982computationally,
  title={A computationally efficient quadrature procedure for the one-factor multinomial probit model},
  author={Butler, John S and Moffitt, Robert},
  journal={Econometrica: Journal of the Econometric Society},
  pages={761--764},
  year={1982},
  publisher={JSTOR}
}

@article{keane1994computationally,
  title={A computationally practical simulation estimator for panel data},
  author={Keane, Michael P},
  journal={Econometrica: Journal of the Econometric Society},
  pages={95--116},
  year={1994},
  publisher={JSTOR}
}

@article{hajivassiliou1996simulation,
  title={Simulation of multivariate normal rectangle probabilities and their derivatives theoretical and computational results},
  author={Hajivassiliou, Vassilis and McFadden, Daniel and Ruud, Paul},
  journal={Journal of econometrics},
  volume={72},
  number={1-2},
  pages={85--134},
  year={1996},
  publisher={Elsevier}
}

@article{geweke1989bayesian,
  title={Bayesian inference in econometric models using Monte Carlo integration},
  author={Geweke, John},
  journal={Econometrica: Journal of the Econometric Society},
  pages={1317--1339},
  year={1989},
  publisher={JSTOR}
}

@misc{geweke1991efficient,
  title={Efficient simulation from the multivariate normal and student-t distributions subject to linear constraints and the evaluation of constraint probabilities},
  author={Geweke, John},
  year={1991},
  publisher={Seattle, USA}
}

@article{geweke1994alternative,
  title={Alternative computational approaches to inference in the multinomial probit model},
  author={Geweke, John and Keane, Michael and Runkle, David},
  journal={The review of economics and statistics},
  pages={609--632},
  year={1994},
  publisher={JSTOR}
}

@book{beal2003variational,
  title={Variational algorithms for approximate Bayesian inference},
  author={Beal, Matthew James},
  year={2003},
  publisher={university of London London}
}

@inproceedings{beal2003,
  author       = {Beal, Matthew James and Ghahramani, Z},
  editor       = {José M. Bernardo and A. Philip Dawid and James O. Berger and Mike West and David Heckerman and M.J. Bayarri and Adrian F.M. Smith},
  title        = {{The variational Bayesian EM algorithm for incomplete data: With application to scoring graphical model structures}},
  date         = {2003},
  booktitle    = {Bayesian Statistics 7},
%  booksubtitle = {Relativistic groups and analyticity},
  booktitleaddon= {Proceedings of the Seventh Valencia International Meeting},
%  eventdate    = {1968-05-19/1968-05-25},
%  venue        = {Aspen{\"a}sgarden, Lerum},
  publisher    = {Oxford University Press},
  location     = {Oxford},
  pages        = {453--464}
}


@article{alvarez2014bayesian,
  title={Bayesian inference for a covariance matrix},
  author={Alvarez, Ignacio and Niemi, Jarad and Simpson, Matt},
  journal={arXiv preprint arXiv:1408.4050},
  year={2014}
}

@inproceedings{teh2007collapsed,
  title={A collapsed variational Bayesian inference algorithm for latent Dirichlet allocation},
  author={Teh, Yee W and Newman, David and Welling, Max},
  booktitle={Advances in neural information processing systems},
  pages={1353--1360},
  year={2007}
}

@article{zhang2013kronecker,
  title={On the Kronecker products and their applications},
  author={Zhang, Huamin and Ding, Feng},
  journal={Journal of Applied Mathematics},
  volume={2013},
  year={2013},
  publisher={Hindawi}
}

@article{marsaglia2000ziggurat,
  title={The ziggurat method for generating random variables},
  author={Marsaglia, George and Tsang, Wai Wan},
  journal={Journal of statistical software},
  volume={5},
  number={8},
  pages={1--7},
  year={2000}
}

%@article{marsaglia1984fast,
%  title={A fast, easily implemented method for sampling from decreasing or symmetric unimodal density functions},
%  author={Marsaglia, George and Tsang, Wai Wan},
%  journal={SIAM Journal on scientific and statistical computing},
%  volume={5},
%  number={2},
%  pages={349--359},
%  year={1984},
%  publisher={SIAM}
%}

@article{chopin2011fast,
  title={Fast simulation of truncated Gaussian distributions},
  author={Chopin, Nicolas},
  journal={Statistics and Computing},
  volume={21},
  number={2},
  pages={275--288},
  year={2011},
  publisher={Springer}
}

@article{damien2001sampling,
  title={Sampling truncated normal, beta, and gamma densities},
  author={Damien, Paul and Walker, Stephen G},
  journal={Journal of Computational and Graphical Statistics},
  volume={10},
  number={2},
  pages={206--215},
  year={2001},
  publisher={Taylor \& Francis}
}

@article{robert1995simulation,
  title={Simulation of truncated normal variables},
  author={Robert, Christian P},
  journal={Statistics and computing},
  volume={5},
  number={2},
  pages={121--125},
  year={1995},
  publisher={Springer}
}

@article{groves1969note,
  title={A note on the expected value of an inverse matrix},
  author={Groves, Theodore and Rothenberg, Thomas},
  journal={Biometrika},
  volume={56},
  number={3},
  pages={690--691},
  year={1969},
  publisher={Oxford University Press}
}

@article{meng1997algorithm,
  title={The EM Algorithm—an Old Folk-song Sung to a Fast New Tune},
  author={Meng, Xiao-Li and Van Dyk, David},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={59},
  number={3},
  pages={511--567},
  year={1997},
  publisher={Wiley Online Library}
}

@Article{jamil2017,
  author  = {Haziq Jamil and Wicher Bergsma},
  title   = {iprior: {An R Package for Regression Modelling using I-priors}},
  journal = {Manuscript in submission},
  year    = {2017},
}

@Article{bergsma2017,
  author  = {Wicher Bergsma},
  title   = {{Regression with I-priors}},
  journal = {Unpublished manuscript},
  year    = {2017},
}

@Misc{R,
  title = {\proglang{R}: {A} Language and Environment for Statistical Computing},
  author = {{\proglang{R} Core Team}},
  organization = {\proglang{R} Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2017},
  url = {https://www.R-project.org/},
}

@article{jaynes1957a,
  title={Information Theory and Statistical Mechanics},
  author={Jaynes, Edwin T},
  journal={Physical Review},
  volume={106},
  number={4},
  pages={620},
  year={1957},
  publisher={APS}
}

@article{jaynes1957b,
  title={Information Theory and Statistical Mechanics II},
  author={Jaynes, Edwin T},
  journal={Physical Review},
  volume={108},
  number={2},
  pages={171},
  year={1957},
  publisher={APS}
}

@book{jaynes2003probability,
  title={Probability Theory: The Logic of Science},
  author={Jaynes, Edwin T},
  year={2003},
  publisher={Cambridge University Press}
}

@book{skorohod2012integration,
  title={Integration in Hilbert Space},
  author={Skorohod, Anatolij Vladimirovi{\v{c}}},
  volume={79},
  year={2012},
  publisher={Springer-Verlag},
  doi={10.1007/978-3-642-65632-3}
}

@incollection{lifshits2012lectures,
  title={Lectures on Gaussian processes},
  author={Lifshits, Mikhail},
  booktitle={Lectures on Gaussian Processes},
  pages={1--117},
  year={2012},
  publisher={Springer-Verlag},
  doi={10.1007/978-3-642-24939-6}
}

@book{rasmussen2006gaussian,
  title={Gaussian Processes for Machine Learning},
  author={Rasmussen, Carl Edward and Williams, Christopher K I},
  year={2006},
  publisher={The MIT Press}
}

@article{eddelbuettel2011rcpp,
   author = {Dirk Eddelbuettel and Romain Francois},
   title = {\pkg{Rcpp}: Seamless \proglang{R} and \proglang{C++} Integration},
   journal = {Journal of Statistical Software},
   volume = {40},
   number = {8},
   year = {2011},
   keywords = {},
   abstract = {The Rcpp package simplifies integrating C++ code with R. It provides a consistent C++ class hierarchy that maps various types of R objects (vectors, matrices, functions, environments, . . . ) to dedicated C++ classes. Object interchange between R and C++ is managed by simple, flexible and extensible concepts which include broad support for C++ Standard Template Library idioms. C++ code can both be compiled, linked and loaded on the fly, or added via packages. Flexible error and exception code handling is provided. Rcpp substantially lowers the barrier for programmers wanting to combine C++ code with R.},

   pages = {1--18},
   doi = {10.18637/jss.v040.i08}
   
}
% issn = {1548-7660}, url = {https://www.jstatsoft.org/v040/i08}

@article{lunn2000winbugs,
author="Lunn, David J.
and Thomas, Andrew
and Best, Nicky
and Spiegelhalter, David",
title="WinBUGS - A Bayesian modelling framework: Concepts, structure, and extensibility",
journal="Statistics and Computing",
year="2000",
month="Oct",
day="01",
volume="10",
number="4",
pages="325--337",
abstract="WinBUGS is a fully extensible modular framework for constructing and analysing Bayesian full probability models. Models may be specified either textually via the BUGS language or pictorially using a graphical interface called DoodleBUGS. WinBUGS processes the model specification and constructs an object-oriented representation of the model. The software offers a user-interface, based on dialogue boxes and menu commands, through which the model may then be analysed using Markov chain Monte Carlo techniques. In this paper we discuss how and why various modern computing concepts, such as object-orientation and run-time linking, feature in the software's design. We also discuss how the framework may be extended. It is possible to write specific applications that form an apparently seamless interface with WinBUGS for users with specialized requirements. It is also possible to interface with WinBUGS at a lower level by incorporating new object types that may be used by WinBUGS without knowledge of the modules in which they are implemented. Neither of these types of extension require access to, or even recompilation of, the WinBUGS source-code.",
doi="10.1023/A:1008929526011"
}
% issn="1573-1375",

@inproceedings{plummer2003jags,
  title={\proglang{JAGS}: A Program for Analysis of Bayesian Graphical Models Using Gibbs Sampling},
  author={Plummer, Martyn},
  booktitle={Proceedings of the 3rd International Workshop on Distributed Statistical Computing},
  volume={124},
  pages={125},
  year={2003},
  organization={Vienna, Austria}
}

@article{sturtz2005r2winbugs,
   author = {Sibylle Sturtz and Uwe Ligges and Andrew Gelman},
   title = {\pkg{R2WinBUGS}: A Package for Running WinBUGS from \proglang{R}},
   journal = {Journal of Statistical Software},
   volume = {12},
   number = {3},
   year = {2005},
   keywords = {},
   abstract = {The R2WinBUGS package provides convenient functions to call WinBUGS from R. It automatically writes the data and scripts in a format readable by WinBUGS for processing in batch mode, which is possible since version 1.4. After the WinBUGS process has finished, it is possible either to read the resulting data into R by the package itself--which gives a compact graphical summary of inference and convergence diagnostics--or to use the facilities of the coda package for further analyses of the output. Examples are given to demonstrate the usage of this package.},
   pages = {1--16},
   doi = {10.18637/jss.v012.i03}
}
% issn = {1548-7660},

@article{denwood2016runjags,
   author = {Matthew Denwood},
   title = {\pkg{runjags}: An \proglang{R} Package Providing Interface Utilities, Model Templates, Parallel Computing Methods and Additional Distributions for MCMC Models in \proglang{JAGS}},
   journal = {Journal of Statistical Software},
   volume = {71},
   number = {9},
   year = {2016},
   keywords = {MCMC; Bayesian; graphical models; interface utilities; JAGS; BUGS; R},
   abstract = {The runjags package provides a set of interface functions to facilitate running Markov chain Monte Carlo models in JAGS from within R. Automated calculation of appropriate convergence and sample length diagnostics, user-friendly access to commonly used graphical outputs and summary statistics, and parallelized methods of running JAGS are provided. Template model specifications can be generated using a standard lme4-style formula interface to assist users less familiar with the BUGS syntax. Automated simulation study functions are implemented to facilitate model performance assessment, as well as drop-k type cross-validation studies, using high performance computing clusters such as those provided by parallel. A module extension for JAGS is also included within runjags, providing the Pareto family of distributions and a series of minimally-informative priors including the DuMouchel and half-Cauchy priors. This paper outlines the primary functions of this package, and gives an illustration of a simulation study to assess the sensitivity of two equivalent model formulations to different prior distributions.},
   pages = {1--25},
   doi = {10.18637/jss.v071.i09}
}
% issn = {1548-7660}, url = {https://www.jstatsoft.org/v071/i09}

@article{carpenter2016stan,
  title={\proglang{Stan}: A Probabilistic Programming Language},
   author = {Bob Carpenter and Andrew Gelman and Matthew Hoffman and Daniel Lee and Ben Goodrich and Michael Betancourt and Marcus Brubaker and Jiqiang Guo and Peter Li and Allen Riddell},
   journal = {Journal of Statistical Software, Articles},
   volume = {76},
   number = {1},
   year = {2017},
   keywords = {probabilistic programming; Bayesian inference; algorithmic differentiation; Stan},
   abstract = {Stan is a probabilistic programming language for specifying statistical models. A Stan program imperatively defines a log probability function over parameters conditioned on specified data and constants. As of version 2.14.0, Stan provides full Bayesian inference for continuous-variable models through Markov chain Monte Carlo methods such as the No-U-Turn sampler, an adaptive form of Hamiltonian Monte Carlo sampling. Penalized maximum likelihood estimates are calculated using optimization methods such as the limited memory Broyden-Fletcher-Goldfarb-Shanno algorithm. Stan is also a platform for computing log densities and their gradients and Hessians, which can be used in alternative algorithms such as variational Bayes, expectation propagation, and marginal inference using approximate integration. To this end, Stan is set up so that the densities, gradients, and Hessians, along with intermediate quantities of the algorithm such as acceptance probabilities, are easily accessible. Stan can be called from the command line using the cmdstan package, through R using the rstan package, and through Python using the pystan package. All three interfaces support sampling and optimization-based inference with diagnostics and posterior analysis. rstan and pystan also provide access to log probabilities, gradients, Hessians, parameter transforms, and specialized plotting.},
   pages = {1--32},
   doi = {10.18637/jss.v076.i01},
}
% issn = {1548-7660}, url = {https://www.jstatsoft.org/v076/i01}

@Misc{rstan,
  title = {\pkg{RStan}: The \proglang{R} Interface to \proglang{Stan}},
  author = {{Stan Development Team}},
  note = {\proglang{R} package version 2.14.1},
  year = {2016},
  url = {http://mc-stan.org/},
}

@article{quinonero2005unifying,
  title={A Unifying View of Sparse Approximate Gaussian Process Regression},
  author={Qui{\~n}onero-Candela, Joaquin and Rasmussen, Carl Edward},
  journal={Journal of Machine Learning Research},
  volume={6},
  month={Dec},
  pages={1939--1959},
  year={2005}
}

@inproceedings{williams2001using,
  title={Using the Nystr{\"o}m Method to Speed Up Kernel Machines},
  author={Williams, Christopher K I and Seeger, Matthias},
  booktitle={Advances in Neural Information Processing Systems 13},
  pages={682--688},
  year={2001},
  publisher={The MIT Press}
}

@inproceedings{fowlkes2001efficient,
  author={C Fowlkes and S Belongie and J Malik}, 
  booktitle={Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2001)}, 
  title={Efficient Spatiotemporal Grouping Using the Nystr\"om Method}, 
  year={2001}, 
  volume={1}, 
  number={}, 
  pages={231--238}, 
  keywords={eigenvalues and eigenfunctions;image segmentation;image sequences;video signal processing;Nystrom method;coherent groups;efficient spatiotemporal grouping;eigenfunction problems;extrapolation;image segmentation;numerical solution;pairwise voxel similarities;spectral graph theoretic methods;spectral partitioning;video sequence;Computer applications;Educational institutions;Eigenvalues and eigenfunctions;Extrapolation;Image segmentation;Image sequences;Pixel;Psychology;Spatiotemporal phenomena;Video sequences}, 
  doi={10.1109/CVPR.2001.990481}, 
  month={}
}
% ISSN={1063-6919}, 

@article{zeileis2004kernlab,
   author = {Alexandros Karatzoglou and Alexandros Smola and Kurt Hornik and Achim Zeileis},
   title = {\pkg{kernlab} - An \proglang{S4} Package for Kernel Methods in \proglang{R}},
   journal = {Journal of Statistical Software},
   volume = {11},
   number = {9},
   year = {2004},
   keywords = {},
   abstract = {kernlab is an extensible package for kernel-based machine learning methods in R. It takes advantage of R's new S4 ob ject model and provides a framework for creating and using kernel-based algorithms. The package contains dot product primitives (kernels), implementations of support vector machines and the relevance vector machine, Gaussian processes, a ranking algorithm, kernel PCA, kernel CCA, and a spectral clustering algorithm. Moreover it provides a general purpose quadratic programming solver, and an incomplete Cholesky decomposition method.},
   pages = {1--20},
   doi = {10.18637/jss.v011.i09},
}
% issn = {1548-7660}, url = {https://www.jstatsoft.org/v011/i09}

@Misc{gpfda,
  title = {\pkg{GPFDA}: Apply Gaussian Process in Functional Data Analysis},
  author = {Jian Qing Shi and Yafeng Cheng},
  year = {2014},
  note = {\proglang{R} package version 2.2},
  url = {https://CRAN.R-project.org/package=GPFDA},
}

@article{macdonald2015gpfit,
  title={\pkg{GPfit}: An \proglang{R} Package for Fitting a Gaussian Process Model to Deterministic Simulator Outputs},
  author = {Blake MacDonald and Pritam Ranjan and Hugh Chipman},
  journal = {Journal of Statistical Software},
  volume = {64},
  number = {12},
  year = {2015},
  keywords = {},
  abstract = {Gaussian process (GP) models are commonly used statistical metamodels for emulating expensive computer simulators. Fitting a GP model can be numerically unstable if any pair of design points in the input space are close together. Ranjan, Haynes, and Karsten (2011) proposed a computationally stable approach for fitting GP models to deterministic computer simulators. They used a genetic algorithm based approach that is robust but computationally intensive for maximizing the likelihood. This paper implements a slightly modified version ofthe model proposed by Ranjan et al.  (2011 ) in the R  package GPfit. A novel parameterization of the spatial correlation function and a clustering based multi-start gradient based optimization algorithm yield robust optimization that is typically faster than the genetic algorithm based approach. We present two examples with R  codes to illustrate the usage of the main functions in GPfit . Several test functions are used for performance comparison with the popular R  package mlegp . We also use GPfit  for a real application, i.e., for emulating the tidal kinetic energy model for the Bay of Fundy, Nova Scotia, Canada. GPfit  is free software and distributed under the General Public License and available from the Comprehensive R Archive Network.},
  pages = {1--23},
  doi = {10.18637/jss.v064.i12},
}
% issn = {1548-7660}, url = {https://www.jstatsoft.org/v064/i12}


@Misc{gptk,
  title = {\pkg{gptk}: Gaussian Processes Tool-Kit},
  author = {Alfredo Kalaitzis and Antti Honkela and Pei Gao and Neil D Lawrence},
  year = {2014},
  note = {\proglang{R} package version 1.08},
  url = {https://CRAN.R-project.org/package=gptk},
}

@article{kalaitzis2011simple,
  author="Kalaitzis, Alfredo 
  and Lawrence, Neil D",
  title="A Simple Approach to Ranking Differentially Expressed Gene Expression Time Courses through Gaussian Process Regression",
  journal="BMC Bioinformatics",
  year="2011",
  month="May",
  day="20",
  volume="12",
  number="1",
  pages="180",
  abstract="The analysis of gene expression from time series underpins many biological studies. Two basic forms of analysis recur for data of this type: removing inactive (quiet) genes from the study and determining which genes are differentially expressed. Often these analysis stages are applied disregarding the fact that the data is drawn from a time series. In this paper we propose a simple model for accounting for the underlying temporal nature of the data based on a Gaussian process.",
  doi="10.1186/1471-2105-12-180"
}
% issn="1471-2105"

@article{bates2014lme4,
  author = {Douglas Bates and Martin Mächler and Ben Bolker and Steve Walker},
  title = {Fitting Linear Mixed-Effects Models Using \pkg{lme4}},
  journal = {Journal of Statistical Software},
  volume = {67},
  number = {1},
  year = {2015},
  keywords = {sparse matrix methods; linear mixed models; penalized least squares; Cholesky decomposition},
  abstract = {Maximum likelihood or restricted maximum likelihood (REML) estimates of the parameters in linear mixed-effects models can be determined using the lmer function in the lme4 package for R. As for most model-fitting functions in R, the model is described in an lmer call by a formula, in this case including both fixed- and random-effects terms. The formula and data together determine a numerical representation of the model from which the profiled deviance or the profiled REML criterion can be evaluated as a function of some of the model parameters. The appropriate criterion is optimized, using one of the constrained optimization functions in R, to provide the parameter estimates. We describe the structure of the model, the steps in evaluating the profiled deviance or REML criterion, and the structure of classes or types that represents such a model. Sufficient detail is included to allow specialization of these structures by users who wish to write functions to fit specialized linear mixed models, such as models incorporating pedigrees or smoothing splines, that are not easily expressible in the formula language used by lmer.},
  pages = {1--48},
  doi = {10.18637/jss.v067.i01}
}
% issn = {1548-7660}

@Misc{rstanarm,
  title = {\pkg{rstanarm}: Bayesian Applied Regression Modeling via \proglang{Stan}},
  author = {{Stan Development Team}},
  note = {\proglang{R} package version 2.13.1},
  year = {2016},
  url = {http://mc-stan.org/},
}

@article{buerkner2016brms,
  author = {Paul-Christian B\"urkner},
  title = {\proglang{brms}: An \proglang{R} Package for Bayesian Multilevel Models Using \proglang{Stan}},
  journal = {Journal of Statistical Software},
  volume = {80},
  number = {1},
  year = {2017},
  keywords = {Bayesian inference; multilevel model; ordinal data; MCMC; Stan; R},
  abstract = {The brms package implements Bayesian multilevel models in R using the probabilistic programming language Stan. A wide range of distributions and link functions are supported, allowing users to fit  -  among others  -  linear, robust linear, binomial, Poisson, survival, ordinal, zero-inflated, hurdle, and even non-linear models all in a multilevel context. Further modeling options include autocorrelation of the response variable, user defined covariance structures, censored data, as well as meta-analytic standard errors. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their beliefs. In addition, model fit can easily be assessed and compared with the Watanabe-Akaike information criterion and leave-one-out cross-validation.},
  pages = {1--28},
  doi = {10.18637/jss.v080.i01}
}
% issn = {1548-7660}

@Book{mgcv,
  title = {Generalized Additive Models: An Introduction with \proglang{R}},
  year = {2017},
  author = {Simon N Wood},
  edition = {2nd},
  publisher = {Chapman and Hall/CRC},
}

@Misc{fda,
  title = {\pkg{fda}: Functional Data Analysis},
  author = {J. O. Ramsay and Hadley Wickham and Spencer Graves and Giles Hooker},
  year = {2017},
  note = {\proglang{R} package version 2.4.7},
  url = {https://CRAN.R-project.org/package=fda},
}

@book{bishop2006pattern,
  title={Pattern Recognition and Machine Learning},
  author={Bishop, Christopher},
  year={2006},
  publisher={Springer-Verlag},
}

@inproceedings{gretton2005measuring,
  author="Gretton, Arthur
  and Bousquet, Olivier
  and Smola, Alex
  and Sch{\"o}lkopf, Bernhard",
  editor="Jain, Sanjay
  and Simon, Hans Ulrich
  and Tomita, Etsuji",
  title="Measuring Statistical Dependence with Hilbert-Schmidt Norms",
  bookTitle="Proceedings of the 16th International Conference of Algorithmic Learning Theory",
  year="2005",
  publisher="Springer-Verlag",
  pages="63--77",
  abstract="We propose an independence criterion based on the eigenspectrum of covariance operators in reproducing kernel Hilbert spaces (RKHSs), consisting of an empirical estimate of the Hilbert-Schmidt norm of the cross-covariance operator (we term this a Hilbert-Schmidt Independence Criterion, or HSIC). This approach has several advantages, compared with previous kernel-based independence criteria. First, the empirical estimate is simpler than any other kernel dependence test, and requires no user-defined regularisation. Second, there is a clearly defined population quantity which the empirical estimate approaches in the large sample limit, with exponential convergence guaranteed between the two: this ensures that independence tests based on HSIC do not suffer from slow learning rates. Finally, we show in the context of independent component analysis (ICA) that the performance of HSIC is competitive with that of previously published kernel-based criteria, and of other recently published ICA methods.",
  doi="10.1007/11564089_7"
}
% isbn="978-3-540-31696-1",

@Misc{foreach,
  title = {\pkg{foreach}: Provides Foreach Looping Construct for \proglang{R}},
  author = {{Revolution Analytics} and Steve Weston},
  year = {2015},
  note = {\proglang{R} package version 1.4.3},
  url = {https://CRAN.R-project.org/package=foreach},
}

@Misc{dosnow,
  title = {\pkg{doSNOW}: Foreach Parallel Adaptor for the \pkg{snow} Package},
  author = {{Microsoft Corporation} and Stephen Weston},
  year = {2017},
  note = {\proglang{R} package version 1.0.15},
  url = {https://CRAN.R-project.org/package=doSNOW},
}

@Misc{caret,
  title = {\pkg{caret}: Classification and Regression Training},
  author = {Max Kuhn and others},
  year = {2017},
  note = {\proglang{R} package version 6.0--77},
  url = {https://CRAN.R-project.org/package=caret},
}

@article{vila2000bayesian,
  author={J. P. Vila and V. Wagner and P. Neveu}, 
  journal={IEEE Transactions on Neural Networks}, 
  title={Bayesian Nonlinear Model Selection and Neural Networks: A Conjugate Prior Approach}, 
  year={2000}, 
  volume={11}, 
  number={2}, 
  pages={265-278}, 
  keywords={Bayes methods;belief networks;decision theory;feedforward neural nets;probability;statistical analysis;Bayesian nonlinear model selection;Gaussian likelihood;conjugate prior approach;embedded models;empirical Bayes-like approach;expected utility criterion;general Bayesian nonlinear regression model comparison procedure;internal consistency;model posterior predictive density;predictive neural-network architecture;predictive probability distribution;training set;Bayesian methods;Distributed computing;Feedforward neural networks;Function approximation;Network topology;Neural networks;Predictive models;Probability distribution;Testing;Utility theory}, 
  doi={10.1109/72.838999}, 
  month={March}
}

@book{ferraty2006nonparametric,
  title={Nonparametric Functional Data Analysis},
  author={Ferraty, Fr{\'e}d{\'e}ric and Vieu, Philippe},
  year={2006},
  publisher={Springer-Verlag},
  doi={10.1007/0-387-36620-2},
  edition={1st}
}

@article{chen2011single,
  title={Single and Multiple Index Functional Regression Models with Nonparametric Link},
  author={Chen, Dong and Hall, Peter and M{\"u}ller, Hans-Georg},
  journal={The Annals of Statistics},
  volume={39},
  number={3},
  pages={1720--1747},
  year={2011},
  publisher={The Institute of Mathematical Statistics},
  doi={10.1214/11-AOS882}
}

@incollection{goia2014some,
  title={Some Advances in Semiparametric Functional Data Modelling},
  author={Goia, Aldo and Vieu, Philippe},
  booktitle={Contributions in Infinite-Dimensional Statistics and Related Topics},
  pages={135--141},
  year={2014},
  publisher={Societa Editrice Esculapio},
  doi={10.15651/978-88-748-8763-7}
}

@article{lian2014series,
  title = "Series Expansion for Functional Sufficient Dimension Reduction",
  journal = "Journal of Multivariate Analysis",
  volume = "124",
  number = "C",
  pages = "150--165",
  year = "2014",
  doi = "10.1016/j.jmva.2013.10.019",
  author = "Heng Lian and Gaorong Li",
  keywords = "Functional principal component analysis, Polynomial splines, Sliced average variance estimation, Sliced inverse regression"
}

@article{zhu2014structured,
  author = {Zhu, Hongxiao and Yao, Fang and Zhang, Hao Helen},
  title = {Structured Functional Additive Regression in Reproducing Kernel Hilbert Spaces},
  journal = {Journal of the Royal Statistical Society B (Statistical Methodology)},
  volume = {76},
  number = {3},
  doi = {10.1111/rssb.12036},
  pages = {581--603},
  keywords = {Additive models, Component selection, Functional data analysis, Principal components, Reproducing kernel Hilbert space, Smoothing spline},
  year = {2014}
}

@Misc{jmcm,
  title = {\pkg{jmcm}: Joint Mean-Covariance Models using \proglang{Armadillo} and \proglang{S4}},
  author = {Jianxin Pan and Yi Pan},
  year = {2016},
  note = {\proglang{R} package version 0.1.7.0},
  url = {https://CRAN.R-project.org/package=jmcm},
}

@article{kenward1987method,
  doi = {10.2307/2347788},  
  abstract = {A method for the comparison of profiles of repeated measurements is described which is based on Gabriel's ante-dependence covariance structure. The method is intended for experiments in which no specific features of the profiles are known to be of interest a priori. The establishment of the appropriate order of ante-dependence structure is discussed and a test statistic for the overall comparison of profiles under the structure is defined. It is shown how this statistic can be decomposed into statistically independent components which can be used to investigate the form of the differences among profiles. In particular the use of these components is proposed as an improvement over the practice of calculating a separate t-test for each time of measurement. All the statistics described can be constructed from standard analysis of covariance sums of squares.},
  author = {Michael G. Kenward},
  journal = {Journal of the Royal Statistical Society C (Applied Statistics)},
  number = {3},
  pages = {296-308},
  title = {A Method for Comparing Profiles of Repeated Measurements},
  volume = {36},
  year = {1987}
}

@book{davidian1995nonlinear,
  title={Nonlinear Models for Repeated Measurement Data},
  author={Davidian, Marie and Giltinan, David M},
  year={1995},
  publisher={Chapman and Hall/CRC}
}

@book{pinheiro2000mixed,
  title={Mixed-Effects Models in S and S-plus},
  author={Pinheiro, Jos{\'e} C and Bates, Douglas M},
  year={2000},
  publisher={Springer-Verlag},
  doi = {10.1007/b98882}
}

@Misc{nlme,
  title = {\pkg{nlme}: Linear and Nonlinear Mixed Effects Models},
  author = {Jos{\'e}o Pinheiro and Douglas Bates and Saikat DebRoy and Deepayan Sarkar and {R Core Team}},
  year = {2017},
  note = {\proglang{R} package version 3.1-131},
  url = {https://CRAN.R-project.org/package=nlme},
}

@book{berlinet2011reproducing,
  title={Reproducing Kernel Hilbert Spaces in Probability and Statistics},
  author={Berlinet, Alain and Thomas-Agnan, Christine},
  year={2011},
  publisher={Springer-Verlag},
  doi = {10.1007/978-1-4419-9096-9}
}

@article{thodberg1996review,
  title={A Review of Bayesian Neural Networks with an Application to near Infrared Spectroscopy},
  author={Thodberg, Hans Henrik},
  journal={IEEE Transactions on Neural Networks},
  volume={7},
  number={1},
  pages={56--72},
  year={1996},
  doi={10.1109/72.478392}
}

@inproceedings{meila2003data,
  title={Data centering in feature space.},
  author={Meila, Marina},
  booktitle={Proceedings of the Ninth International Workshop on Artificial Intelligence
               and Statistics ({AISTATS})},
  year={2003},
  editor={Christopher Bishop and Brendan Frey},
  publisher={Society for Artificial Intelligence and Statistics},
}

@inproceedings{cheng2017variational,
  title={Variational Inference for Gaussian Process Models with Linear Complexity},
  author={Cheng, Ching-An and Boots, Byron},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5190--5200},
  year={2017}
}

@article{kimeldorf1970correspondence,
  title={A correspondence between Bayesian estimation on stochastic processes and smoothing by splines},
  author={Kimeldorf, George S and Wahba, Grace},
  journal={The Annals of Mathematical Statistics},
  volume={41},
  number={2},
  pages={495--502},
  year={1970},
  publisher={JSTOR}
}

@article{ra1922mathematical,
  title={On the mathematical foundations of theoretical statistics},
  author={RA Fisher},
  journal={Phil. Trans. R. Soc. Lond. A},
  volume={222},
  number={594-604},
  pages={309--368},
  year={1922},
  publisher={The Royal Society}
}

@article{efron1978assessing,
  title={Assessing the accuracy of the maximum likelihood estimator: Observed versus expected Fisher information},
  author={Efron, Bradley and Hinkley, David V},
  journal={Biometrika},
  volume={65},
  number={3},
  pages={457--483},
  year={1978},
  publisher={Oxford University Press}
}

@book{pawitan2001all,
  title={In all likelihood: statistical modelling and inference using likelihood},
  author={Pawitan, Yudi},
  year={2001},
  publisher={Oxford University Press}
}

@book{wasserman2013all,
  title={All of statistics: a concise course in statistical inference},
  author={Wasserman, Larry},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@book{steinwart2008support,
  title={Support vector machines},
  author={Steinwart, Ingo and Christmann, Andreas},
  year={2008},
  publisher={Springer Science \& Business Media}
}

@article{mandelbrot1968fractional,
  title={Fractional Brownian motions, fractional noises and applications},
  author={Mandelbrot, Benoit B and Van Ness, John W},
  journal={SIAM review},
  volume={10},
  number={4},
  pages={422--437},
  year={1968},
  publisher={SIAM}
}

@incollection{cohen2002,
  title={Champs localement auto-similaires},
  booktitle={Lois d'{\'e}chelle, fractales et ondelettes},
  author={S Cohen},
  editor={Abry, Patrice and Gon{\c{c}}alves, Paulo and V{\'e}hel, Jacques L{\'e}vy},
  volume={1},
  year={2002},
  publisher={Herm{\`e}s Sciences Publications}
}

@book{embrechts2002selfsimilar,
  title={Selfsimilar Processes. Princeton series in applied mathematics},
  author={Embrechts, Paul and Maejima, Makoto},
  year={2002},
  publisher={Princeton University Press, Princeton, NJ}
}

@phdthesis{duvenaud2014automatic,
  title={Automatic model construction with Gaussian processes},
  author={Duvenaud, David},
  year={2014},
  school={University of Cambridge}
}

@article{steinwart2006explicit,
  title={An explicit description of the reproducing kernel Hilbert spaces of Gaussian RBF kernels},
  author={Steinwart, Ingo and Hush, Don and Scovel, Clint},
  journal={IEEE Transactions on Information Theory},
  volume={52},
  number={10},
  pages={4635--4643},
  year={2006},
  publisher={IEEE}
}

@article{micchelli2006universal,
  title={Universal kernels},
  author={Micchelli, Charles A and Xu, Yuesheng and Zhang, Haizhang},
  journal={Journal of Machine Learning Research},
  volume={7},
  number={Dec},
  pages={2651--2667},
  year={2006}
}

@article{kree1974produits,
  title={Produits tensoriels compl{\'e}t{\'e}s d’espaces de Hilbert},
  author={Kr{\'e}e, Paul},
  journal={S{\'e}minaire Paul Kr{\'e}e},
  volume={1},
  number={7},
  pages={1974--1975},
  year={1974},
  publisher={Secr{\'e}tariat math{\'e}matique}
}

@misc{reed1972methods,
  title={Methods of mathematical physics I: Functional analysis},
  author={Reed, Michael and Simon, Barry},
  year={1972},
  publisher={Academic Press New York}
}

@book{casella2002statistical,
  title={Statistical inference},
  author={Casella, George and Berger, Roger L},
  volume={2},
  year={2002},
  publisher={Duxbury Pacific Grove, CA}
}

@book{dean1999design,
  title={Design and analysis of experiments},
  author={Dean, Angela and Voss, Daniel},
  volume={1},
  year={1999},
  publisher={Springer}
}

@book{gu2013smoothing,
  title={Smoothing spline ANOVA models},
  author={Gu, Chong},
  volume={297},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@article{kuo2010decompositions,
  title={On decompositions of multivariate functions},
  author={Kuo, F and Sloan, I and Wasilkowski, G and Wo{\'z}niakowski, Henryk},
  journal={Mathematics of computation},
  volume={79},
  number={270},
  pages={953--966},
  year={2010}
}

@article{sobol2001global,
  title={Global sensitivity indices for nonlinear mathematical models and their Monte Carlo estimates},
  author={Sobol, Ilya M},
  journal={Mathematics and computers in simulation},
  volume={55},
  number={1-3},
  pages={271--280},
  year={2001},
  publisher={Elsevier}
}

@article{durrande2013anova,
  title={ANOVA kernels and RKHS of zero mean functions for model-based sensitivity analysis},
  author={Durrande, Nicolas and Ginsbourger, David and Roustant, Olivier and Carraro, Laurent},
  journal={Journal of Multivariate Analysis},
  volume={115},
  pages={57--67},
  year={2013},
  publisher={Elsevier}
}

@book{rudin1987real,
  title={Real and complex analysis},
  author={Rudin, Walter},
  year={1987},
  publisher={Tata McGraw-Hill Education}
}

@inproceedings{ong2004learning,
  title={Learning with non-positive kernels},
  author={Ong, Cheng Soon and Mary, Xavier and Canu, St{\'e}phane and Smola, Alexander J},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={81},
  year={2004},
  organization={ACM}
}

@phdthesis{mary2003hilbertian,
  title={Hilbertian subspaces, subdualities and applications},
  author={Mary, Xavier},
  year={2003},
  school={INSA de Rouen}
}

@article{alpay1991some,
  title={Some remarks on reproducing kernel Krein spaces},
  author={Alpay, Daniel},
  journal={The Rocky Mountain Journal of Mathematics},
  pages={1189--1205},
  year={1991},
  publisher={JSTOR}
}

@article{sejdinovic2012,
author = {Sejdinovic, Dino and Gretton, Arthur},
file = {:Users/haziqjamil/Documents/Mendeley Desktop/Sejdinovic, Gretton/COMPGI13 Advanced Topics in Machine Learning. Lecture conducted at University College London/Sejdinovic, Gretton - 2012 - Lecture notes What is an RKHS.pdf:pdf},
journal = {COMPGI13 Advanced Topics in Machine Learning. Lecture conducted at University College London},
pages = {1--24},
title = {{Lecture notes: What is an RKHS?}},
url = {http://www.gatsby.ucl.ac.uk/{~}gretton/coursefiles/RKHS{\_}Notes1.pdf},
year = {2012}
}

@inproceedings{zafeiriou2012subspace,
  title={Subspace learning in krein spaces: Complete kernel fisher discriminant analysis with indefinite kernels},
  author={Zafeiriou, Stefanos},
  booktitle={European Conference on Computer Vision},
  pages={488--501},
  year={2012},
  organization={Springer}
}

@book{balakrishnan1981applied,
  title={Applied Functional Analysis},
  author={Balakrishnan, Alampallam V},
  edition={2},
  volume={3},
  year={1981},
  publisher={Springer Science \& Business Media},
  doi={10.1007/978-1-4612-5865-0}
}

@article{bouboulis2011extension,
  title={Extension of Wirtinger's calculus to reproducing kernel Hilbert spaces and the complex kernel LMS},
  author={Bouboulis, Pantelis and Theodoridis, Sergios},
  journal={IEEE Transactions on Signal Processing},
  volume={59},
  number={3},
  pages={964--978},
  year={2011},
  publisher={IEEE}
}

@inproceeding{tapia1971diff,
  title={The differentiation and integration of nonlinear operators},
  author={Tapia, R A},
  booktitle={Nonlinear functional analysis and applications: Proceedings of an advanced seminar conducted by the Mathematics Research Center, the University of Wisconsin, Madison, October 12-14, 1970},
  editor={Rall, Louis B},
  pages={45--101},
  year={1971},
  publisher={Elsevier}
}


@misc{kammar2016,
author={Ohad Kammar},
title={A note on Fréchet diffrentiation under Lebesgue integrals
},
year={2016},
url={https://www.cs.ox.ac.uk/people/ohad.kammar/notes/kammar-a-note-on-frechet-differentiation-under-lebesgue-integrals.pdf}
}

@article{schoenberg1937,
  title={On certain metric spaces arising from Euclidean spaces by a change of metric and their imbedding in Hilbert space},
  author={Schoenberg, Isaac J},
  journal={Annals of mathematics},
  pages={787--793},
  year={1937},
  publisher={JSTOR}
}

@article{hein2004kernels,
  title={Kernels, associated structures and generalizations},
  author={Hein, Matthias and Bousquet, Olivier},
  journal={Max-Planck-Institut fuer biologische Kybernetik, Technical Report},
  year={2004}
}

@book{wahba1990spline,
  title={Spline models for observational data},
  author={Wahba, Grace},
  volume={59},
  year={1990},
  publisher={Siam}
}

@article{zellner1986assessing,
  title={On assessing prior distributions and Bayesian regression analysis with g-prior distributions},
  author={Zellner, Arnold},
  journal={Bayesian inference and decision techniques},
  year={1986},
  publisher={Elsevier Science}
}

@incollection{van2008reproducing,
  title={Reproducing kernel Hilbert spaces of Gaussian priors},
  author={{van der Vaart}, Aad W and {van Zanten}},
  booktitle={Pushing the limits of contemporary statistics: contributions in honor of Jayanta K. Ghosh},
  pages={200--222},
  year={2008},
  publisher={Institute of Mathematical Statistics}
}

@article{wu1983convergence,
  title={On the convergence properties of the EM algorithm},
  author={Wu, CF Jeff},
  journal={The Annals of statistics},
  pages={95--103},
  year={1983},
  publisher={JSTOR}
}

@article{dempster1977maximum,
  title={Maximum likelihood from incomplete data via the EM algorithm},
  author={Dempster, Arthur P and Laird, Nan M and Rubin, Donald B},
  journal={Journal of the royal statistical society. Series B (methodological)},
  pages={1--38},
  year={1977},
  publisher={JSTOR}
}

@article{meng1993maximum,
  title={Maximum likelihood estimation via the ECM algorithm: A general framework},
  author={Meng, Xiao-Li and Rubin, Donald B},
  journal={Biometrika},
  volume={80},
  number={2},
  pages={267--278},
  year={1993},
  publisher={Oxford University Press}
}

@article{bernardo2003variational,
  title={The variational Bayesian EM algorithm for incomplete data: with application to scoring graphical model structures},
  author={Bernardo, JM and Bayarri, MJ and Berger, JO and Dawid, AP and Heckerman, D and Smith, AFM and West, M and others},
  journal={Bayesian statistics},
  volume={7},
  pages={453--464},
  year={2003}
}

@article{yu2012monotonically,
  title={Monotonically overrelaxed EM algorithms},
  author={Yu, Yaming},
  journal={Journal of Computational and Graphical Statistics},
  volume={21},
  number={2},
  pages={518--537},
  year={2012},
  publisher={Taylor \& Francis}
}

@article{liu1998parameter,
  title={Parameter expansion to accelerate EM: The PX-EM algorithm},
  author={Liu, Chuanhai and Rubin, Donald B and Wu, Ying Nian},
  journal={Biometrika},
  volume={85},
  number={4},
  pages={755--770},
  year={1998},
  publisher={Oxford University Press}
}

@article{lange1995quasi,
  title={A quasi-Newton acceleration of the EM algorithm},
  author={Lange, Kenneth},
  journal={Statistica sinica},
  pages={1--18},
  year={1995},
  publisher={JSTOR}
}

@article{petersen2008matrix,
  title={The matrix cookbook},
  author={Petersen, Kaare Brandt and Pedersen, Michael Syskind},
  journal={Technical University of Denmark},
  volume={7},
  number={15},
  pages={510},
  year={2008}
}

@inproceedings{titsias2009variational,
  title={Variational learning of inducing variables in sparse Gaussian processes},
  author={Titsias, Michalis},
  booktitle={Artificial Intelligence and Statistics},
  pages={567--574},
  year={2009}
}

@article{hensman2013gaussian,
  title={Gaussian processes for big data},
  author={Hensman, James and Fusi, Nicolo and Lawrence, Neil D},
  journal={arXiv preprint arXiv:1309.6835},
  year={2013}
}

@article{duane1987hybrid,
  title={Hybrid monte carlo},
  author={Duane, Simon and Kennedy, Anthony D and Pendleton, Brian J and Roweth, Duncan},
  journal={Physics letters B},
  volume={195},
  number={2},
  pages={216--222},
  year={1987},
  publisher={Elsevier}
}

@article{neal2011mcmc,
  title={MCMC using Hamiltonian dynamics},
  author={Neal, Radford M and others},
  journal={Handbook of Markov Chain Monte Carlo},
  volume={2},
  number={11},
  year={2011},
  publisher={CRC Press New York, NY}
}

@article{kass1995bayes,
  title={Bayes factors},
  author={Kass, Robert E and Raftery, Adrian E},
  journal={Journal of the american statistical association},
  volume={90},
  number={430},
  pages={773--795},
  year={1995},
  publisher={Taylor \& Francis Group}
}

@article{carlin1995bayesian,
  title={Bayesian model choice via Markov chain Monte Carlo methods},
  author={Carlin, Bradley P and Chib, Siddhartha},
  journal={Journal of the Royal Statistical Society. Series B (Methodological)},
  pages={473--484},
  year={1995},
  publisher={JSTOR}
}

@article{albert1993bayesian,
  title={Bayesian analysis of binary and polychotomous response data},
  author={Albert, James H and Chib, Siddhartha},
  journal={Journal of the American statistical Association},
  volume={88},
  number={422},
  pages={669--679},
  year={1993},
  publisher={Taylor \& Francis}
}

@BOOK{mccullagh1989,
  TITLE = {Generalized Linear Models},
  AUTHOR = {P. McCullagh and John A. Nelder},
  YEAR = {1989}, 
  PUBLISHER = {Chapman \& Hall/CRC Press},
  Edition = {2nd}
}

@article{blei2017variational,
  title={Variational inference: A review for statisticians},
  author={Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D},
  journal={Journal of the American Statistical Association},
  number={just-accepted},
  year={2017},
  publisher={Taylor \& Francis}
}

@book{itzykson1991statistical,
  title={Statistical Field Theory: Volume 2, Strong Coupling, Monte Carlo Methods, Conformal Field Theory and Random Systems},
  author={Itzykson, Claude and Drouffe, Jean Michel},
  year={1991},
  publisher={Cambridge University Press}
}

@book{mclachlan2007algorithm,
  title={The EM algorithm and extensions},
  author={McLachlan, Geoffrey and Krishnan, Thriyambakam},
  volume={382},
  year={2007},
  publisher={John Wiley \& Sons}
}

@article{hastie1986,
author = "Hastie, Trevor and Tibshirani, Robert",
doi = "10.1214/ss/1177013604",
fjournal = "Statistical Science",
journal = "Statist. Sci.",
month = "08",
number = "3",
pages = "297--310",
publisher = "The Institute of Mathematical Statistics",
title = "Generalized Additive Models",
url = "https://doi.org/10.1214/ss/1177013604",
volume = "1",
year = "1986"
}

@book{scholkopf2002learning,
  title={Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond},
  author={Sch{\"o}lkopf, Bernhard and Smola, Alexander J},
  year={2002},
  publisher={MIT Press}
}

@inproceedings{minka2001expectation,
  title={Expectation propagation for approximate Bayesian inference},
  author={Minka, Thomas P},
  booktitle={Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence},
  pages={362--369},
  year={2001},
  organization={Morgan Kaufmann Publishers Inc.}
}

@incollection{neal1999,
  title={{Regression and Classification using Gaussian Process Priors}},
  author={Radford M. Neal},
  booktitle={Bayesian Statistics},
  editor={Bernardo, J M and Berger, J O and Dawid, A P and Smith, A F M},
  journal={Bayesian statistics},
  volume={6},
  pages={475--501},
  year={1999},
  publisher={Oxford University Press. (with discussion)},
}

@article{girolami2006variational,
  title={{Variational Bayesian Multinomial Probit Regression with Gaussian Process Priors}},
  author={Girolami, Mark and Rogers, Simon},
  journal={Neural Computation},
  volume={18},
  number={8},
  pages={1790--1817},
  year={2006},
  publisher={MIT Press}
}

@Manual{jamil2018riprobit,
  title = {iprobit: Binary and Multinomial Probit Regression with I-priors},
  year={2018},
  author = {Haziq Jamil},
  note = {R package version 0.1.0.9004},
  url = {https://github.com/haziqjamil/iprobit},
}

@article{bergsma2017,
  title={{Regression and Classification with I-priors}},
  author={Bergsma, Wicher},
  journal={Manuscript in preparation. \href{http://arxiv.org/abs/1707.00274}{\normalfont\texttt{arXiv:1707.00274}}},
  year={2017},
  publisher={test},
  address={test1}
}

@article{Keane1992,
abstract = {Although formal conditions for identification in the multinomial probit (MNP) model are now clearly established, little is known about how various estimable MNP specifications perform in practice. This article shows that parameter identification in the MNP model is extremely tenuous in the absence of exclusion restrictions. This previously unnoticed fact is important because formal identification of MNP models does not require exclusion restrictions, and many potential economic applications of MNP are to situations in which exclusion restrictions are not readily available. Thus, failure to be aware of the difficulties present in such situations may lead to reporting of unreliable results.},
author = {Keane, Michael P.},
doi = {10.2307/1391677},
issn = {0735-0015},
journal = {Journal of Business \& Economic Statistics},
keywords = {discrete choice,latent variables,minneapolis,mn 55455,of minnesota,parameter estimability},
mendeley-groups = {probit-iprior},
number = {2},
pages = {193--200},
title = {{A Note on Identification in the Multinomial Probit Model}},
url = {http://www.jstor.org/stable/1391677%5Cnhttp://www.jstor.org/stable/pdfplus/1391677.pdf?acceptTC=true},
volume = {10},
year = {1992}
}

@book{train2009discrete,
  title={Discrete choice methods with simulation},
  author={Train, Kenneth E},
  year={2009},
  publisher={Cambridge university press}
}

@article{mcculloch2000bayesian,
  title={A Bayesian analysis of the multinomial probit model with fully identified parameters},
  author={McCulloch, Robert E and Polson, Nicholas G and Rossi, Peter E},
  journal={Journal of econometrics},
  volume={99},
  number={1},
  pages={173--193},
  year={2000},
  publisher={Elsevier}
}

@article{mcculloch1994exact,
  title={An exact likelihood analysis of the multinomial probit model},
  author={McCulloch, Robert and Rossi, Peter E},
  journal={Journal of Econometrics},
  volume={64},
  number={1},
  pages={207--240},
  year={1994},
  publisher={Elsevier}
}

@article{nobile1998hybrid,
  title={A hybrid Markov chain for the Bayesian analysis of the multinomial probit model},
  author={Nobile, Agostino},
  journal={Statistics and Computing},
  volume={8},
  number={3},
  pages={229--242},
  year={1998},
  publisher={Springer}
}

@book{bishop2006pattern,
  title={Pattern recognition and machine learning},
  author={Bishop, Christopher M},
  year={2006},
  publisher={springer}
}


