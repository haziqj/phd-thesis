%
%\documentclass[english, 11pt]{article}%!TEX root = main.Rnw
%\usepackage{haziq_article}
%\begin{document}

<<include = FALSE, cache = FALSE>>=
# patchDVI options
patchDVI::useknitr()
#.SweaveFiles <- "main.Rnw"
.TexRoot <- "main.tex"
.SweaveMake <- 2

# knitr options
# options(prompt = "> ")
knitr::opts_chunk$set(prompt = FALSE, fig.align = "center", fig.width = 7, fig.height = 5)
knitr::knit_theme$set("bclear")

# Libraries
library(knitr)
library(iprior)
library(devtools)
library(R2MLwiN)
library(lme4)
library(jmcm)
library(caret)
@

In this section, a comparison between a standard random effects model and the I-prior approach for estimating varying intercept and varying slopes model is illustrated. We consider a data set which accompanies the MLwiN software on the academic achievements of 4,059 pupils at 65 inner-London schools \citep{rasbash2012user, R2MLwiN}. The response variable of interest are the pupils' (normalised) GCSE scores at age 16 encoded in the variable \code{normexam}. Also available in the data set is a pupil-specific regressor, which is the London reading test results (\code{standlrt}) for each pupil taken when they were aged 11.

<<dataset1>>=
data(tutorial, package = "R2MLwiN")
str(tutorial[, c("normexam", "school", "standlrt")])
@

<<analysis, include = FALSE, cache = TRUE, cache.lazy = FALSE>>=
# Varying intercept model
# MLE value obtained by running the EM a total of 8 hours
# 120 iterations to complete, max log-lik = -5503.8503
mod1.fit <- iprior(normexam ~ school, data = tutorial,
                   control = list(lambda = 0.0006998815, psi = 1.1799067261,
                                  maxit = 1, silent = TRUE))
int1 <- round(unique(fitted(mod1.fit))[48], 2)
int2 <- round(unique(fitted(mod1.fit))[54], 2)

mod1a <- lmer(normexam ~ 1 + (1 | school), tutorial)
int1a <- round(coef(mod1a)$school[48,], 2)
int2a <- round(coef(mod1a)$school[54,], 2)

# Varying slopes model
# MLE value obtained by running the EM a total of 24 hours!
# 635 iterations to complete, max log-lik = -4670.3808
mod2.fit <- iprior(normexam ~ school * standlrt, data = tutorial,
                   control = list(lambda = c(0.0004234420, 0.37315515627),
                                  psi = 1.8028197426, maxit = 1, silent = TRUE))

mod2a <- lmer(normexam ~ 1 + standlrt + (1 + standlrt | school), tutorial)
@

First, we consider the varying intercept model. A standard approach to fitting this model is the random intercept model, which is based on the assumption that the intercepts are iid normal with zero mean. In \proglang{R}, packages such as \pkg{lme4} are able to fit these types of models. In the I-prior approach, the response variable \code{normexam} is regressed against the covariate \code{school} indicating the school that pupil had attended, which is assumed to have a nominal effect on GCSE scores. In other words, the regression function lies in the Pearson RKHS. As the variable \code{school} is a factor-type variable, the \pkg{iprior} package knows to treat this variable with the Pearson kernel automatically without user specification.

<<iprior1.1.show, eval = FALSE>>=
# Model 1: Varying intercept model
(mod1.fit <- iprior(normexam ~ school, data = tutorial))
@
(output omitted)
<<iprior1.1, echo = FALSE, cache = TRUE, cache.lazy = FALSE>>=
print(mod1.fit)
@

In Figure \ref{fig:plot}(a), the posterior means of the intercepts are plotted for the random effects model and the I-prior model. It can be seen that the estimates are in broad agreement, with conspicuously different estimates for schools 48 (\Sexpr{int1a} vs. \Sexpr{int1}) and 54 (\Sexpr{int2a} vs. \Sexpr{int2}), the I-prior giving the larger estimate in absolute values in both cases. The reason for this is that the I-prior variance for each school's regression function in a Pearson RKHS is inversely proportional to the sample size for that school. A proof of this is given in Appendix \ref{apx:pears}. Indeed, schools 48 and 54 have the smallest sample sizes of all schools, namely 2 and 8 respectively, whilst the next smallest is school 37 with 22 students.

<<plot, echo = FALSE, fig.height = 5, fig.width = 5, out.width = "7cm", out.height = "7cm", fig.show = "hold", fig.cap = "Estimated intercepts and slopes for school achievement data under (a) varying intercept (left); and (b) varying slope model. The numbers plotted are the school indices with the identity line for reference.">>=
plot(x = coef(mod1a)$school[, 1], y = unique(fitted(mod1.fit)), type = "n",
     main = "Varying intercept model",
     xlab = "Standard random effects model estimates (intercepts)",
     ylab = "I-prior estimates (intercepts)")
text(x = coef(mod1a)$school[, 1], y = unique(fitted(mod1.fit)),
     levels(tutorial$school), col = ipriorColPal())
abline(0, 1)

slopes2a <- coef(mod2a)$school[, 2]
slopes2 <- slope(mod2.fit)
indslop <- sort(as.numeric(names(slopes2)), index.return = TRUE)$ix
slopes2 <- slopes2[indslop]

plot(x = slopes2a, y = slopes2, type = "n",
     main = "Varying slopes model",
     xlab = "Standard random effects model estimates (slopes)",
     ylab = "I-prior estimates (slopes)")
text(x = slopes2a, y = slopes2,
     levels(tutorial$school), col = ipriorColPal())
abline(0, 1)
@

Next we consider the varying slope model which regresses, for each school, the GCSE score on the results of the London reading test taken at age 11 (\code{standlrt}). A standard approach to fitting this model is the random intercept/slopes model, which is based on the assumption that the intercept/slope pairs are iid bivariate normal with zero means. To obtain an I-prior, we assume as above a nominal effect of school, and a linear effect of \code{standlrt} (using the canonical kernel on this variable). An interaction between the variables \code{standlrt} and \code{school} imply that the effect of the covariate \code{standlrt} varies with each school.

<<iprior1.2.show, eval = FALSE>>=
# Model 2: Varying slope model
(mod2.fit <- iprior(normexam ~ school * standlrt, data = tutorial))
@
(output omitted)
<<iprior1.2, echo = FALSE, cache = TRUE, cache.lazy = FALSE>>=
# Actual evaluation
print(mod2.fit)
@

In Figure \ref{fig:plot}(b), the posterior means of the slopes obtained using the standard random effects model are plotted against the ones obtained using the I-prior. Again, we see broad agreement of the estimates, but much less so than the varying intercept model.

A limited cross-validation study yielded on average a small advantage of the standard random effects approach in terms of mean squared error, in the order of half a percent, indicating the iid assumption in the random effects models is reasonable. However, an advantage of the I-prior is that no a priori assumption about the distribution of the parameters need to be made. Furthermore, our approach is more parsimonious and allows potentially simpler estimation and testing.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% REFERENCES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\nocite{*}
%\bibliographystyle{apalike}
%\bibliography{haziq}
%\end{document}
