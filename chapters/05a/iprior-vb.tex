%\documentclass[class=article, crop=false]{standalone}
\documentclass{article}
%\ifstandalone
\usepackage{../../haziq_article}
\usepackage{../../knitr}
%\fi

\begin{document}

{\centering
Haziq Jamil \\
\emph{Department of Statistics} \\
\emph{London School of Economics and Political Science} \\
}

\section{Variational inference for I-prior models}

The model:
\begin{align*}
\begin{gathered}
  \by = \balpha + \lambda\bH\bw + \bepsilon \\
  \bepsilon \sim \N(\bzero, \psi^{-1}\bI_n) \\
  \bw \sim \N(\bzero, \psi\bI_n)
\end{gathered}
\end{align*}

Let $\bu \sim \N(\bzero, \psi^{-1} \bI_n)$. Reparameterise $\xi = \lambda\psi$. Then $\psi^{-1}\bw$ will have the same distribution as $\bu$. Substituting this into the I-prior model, we have

\begin{align*}
\begin{gathered}
	\by = \balpha + \xi\bH\bu + \bepsilon \\
	\bu \sim \N (\bzero, \psi^{-1}\bI_n) \\
	\bepsilon \sim \N (\bzero, \psi^{-1}\bI_n)
\end{gathered}
\end{align*}


\subsection{DAG for the I-prior model}

\begin{figure}[H]
\centering
\begin{tikzpicture}
\tikzstyle{main}=[circle, minimum size = 10mm, thick, draw =black!80, node distance = 16mm]
\tikzstyle{connect}=[-latex, thick]
\tikzstyle{box}=[rectangle, draw=black!100]
  \node[main, fill = black!10] (H) [] {$\mathbf H$};
  \node[main] (eta) [right=of H] {$\eta$};
  \node[main] (xi) [above=of eta] {$\xi$};
  \node[main, fill = black!10] (alpha) [below=of H] {$\alpha$};
  \node[main, fill = black!10] (y) [right=of eta] {$y$};
  \node[main] (sigma) [right=of y] {$\psi$};  
  \node[main] (u) [below=of y] {$u$};
%  \node[main, fill = black!10] (x) [below=of eta,label=below:$x$] { };
  \path (sigma) edge [connect] (y)
        (sigma) edge [connect] (u)
        (xi) edge [connect] (eta)
		(H) edge [connect] (eta)
		(eta) edge [connect] (y)
		(alpha) edge [connect] (eta)
		(u) edge [connect] (y);
  \node[rectangle, inner sep=4.4mm, draw=black!100, fit= (u) (eta)] {}; 
  \node[rectangle, inner sep=4.4mm, fit= (u) (eta), label=below right:N, xshift=-0.3cm] {};  % the label
\end{tikzpicture}
\end{figure}

\subsection{Distributions}

\subsubsection{Priors}

\begin{align*}
  \begin{gathered}
    p(u_1,\dots,u_n) \equiv [\N(0,\psi^{-1})]^n \\
    p(\xi,\psi) \propto \const
  \end{gathered}
\end{align*}

\subsubsection{Joint data and latent}

\begin{align*}
  p(\by, \bu, \xi,\psi) 
  &= p(\by | \bu, \xi,\psi) p(\bu, \xi,\psi) \\
  &= p(\by | \bfeta) p(\bu) p(\xi, \psi)
\end{align*}
where
\[
  \bfeta = \balpha + \xi\bH\bu
\]
\subsubsection{pdf/pmf}

\begin{align*}
  \log p(\by | \bfeta) 
  &= \log \N(\bfeta, \psi^{-1}\mathbf I_n) \\
  &= -\half[n] \log 2\pi +\half[n] \log \psi - \half[\psi] \Vert \by - \bfeta \Vert^2 \\
  &= -\half[n] \log 2\pi +\half[n] \log \psi - \half[\psi] \Vert \by - \balpha - \xi \bH \bu \Vert^2 \\
  &= -\half[n] \log 2\pi +\half[n] \log \psi - \half[\psi] \sum_{i=1}^n \left( y_i - \alpha - \xi \bH_i \bu \right)^2 \\
  \\
  \log p(\bu) 
  &= \log \N(\bzero, \psi^{-1}\mathbf I_n) \\
  &= -\half[n] \log 2\pi + \half[n] \log \psi - \half[\psi] \Vert \bu \Vert^2 \\
  &= -\half[n] \log 2\pi + \half[n] \log \psi - \half[\psi] \sum_{i=1}^n u_i^2 \\
\end{align*}

\subsection{Mean field approximation}

\begin{align*}
  q(\bu, \xi, \psi) 
  &\equiv q(\bu)q(\xi)q(\psi) \\
\end{align*}

\subsubsection{Distribution of $\tilde q(\bu)$}

\begin{align*}
  \log \tilde q(\bu) 
  &= \E_{\xi, \psi} \left[ - \half[\psi] \Vert \by - \balpha - \xi \bH \bu \Vert^2 + \Vert \bu \Vert^2\right] + \const \\
  &= - \half[\E\psi] \E_{\xi, \psi} \left[ \xi^2 \bu^\top \mathbf H^2 \bu + \bu^\top\bu - 2\xi(\by - \balpha)^\top\bH\bu \right] + \const \\
  &= - \half[\E\psi] \Big(  \bu^\top (\E[\xi^2]\mathbf H^2 + \bI_n) \bu - 2\E\xi(\by - \balpha)^\top\bH\bu \Big) + \const
\end{align*}

Let $\bA = \E[\xi^2]\mathbf H^2 + \bI_n$ and $\ba = \E[\xi]\bH(\by - \balpha)$. Then, using the fact that
\[
  \bu^\top \bA \bu - 2 \ba^\top\bu = (\bu - \bA^{-1}\ba)^\top\bA(\bu - \bA^{-1}\ba),
\]
we see the $\tilde q(\bu)$ is quadratic in $\bu$, and we recognise this as the kernel of a multivariate normal density. Therefore,
\[
  \tilde q(\bu) \equiv \N(\bA^{-1}\ba, \bA^{-1} / \E\psi)
\]

For convenience later in deriving the lower bound, we note that the second moment of $\tilde q(\bw)$ is equal to $\E[\bu\bu^\top] = \bA^{-1}(\E^{-1}[\psi]\bI_n + \ba\ba^\top\bA^{-1}) =: \btU$.

\subsubsection{Distribution of $\tilde q(\xi)$}

\begin{align*}
  \log \tilde q(\xi) 
  &= \E_{\bu, \psi} \left[ - \half[\psi] \Vert \by - \balpha - \xi \bH \bu \Vert^2  \right] + \const \\
  &= - \half[\E\psi] \E_{\bu, \psi} \left[ \xi^2 \tr(\bH^2\bu\bu^\top) - 2\xi(\by -\balpha)^\top\bH\bu \right] + \const \\
  &= - \half[\E\psi] \Big[ \xi^2 \tr\left(\bH^2\E[\bu\bu^\top]\right) - 2\xi(\by - \balpha)^\top\bH\E\bu \Big] + \const
\end{align*}

By completing the square, we get that $\tilde q(\xi) \equiv \N\big(d/c, (c\E[\psi])^{-1}\big)$, where
\[
  c = \tr\left(\bH^2\E[\bu\bu^\top]\right) \ \text{ and } \ d = (\by - \balpha)^\top\bH\E\bu
\]

\subsubsection{Distribution of $\tilde q(\psi)$}

\begin{align*}
  \log \tilde q(\psi) 
  &= \E_{\bu, \xi} \left[ \half[n] \log \psi - \half[\psi] \Vert \by - \bfeta \Vert^2  +\half[n] \log \psi - \half[\psi] \Vert \bu \Vert^2 \right] + \const \\
  &= n \log \psi  - \E_{\bu, \xi} \left[ \half[\psi] \big( \Vert \by - \bfeta \Vert^2 +\Vert \bu \Vert^2 \big) \right] + \const \\
  &= (n+1-1) \log \psi \\
  &\phantom{==} - \psi \cdot \left( \half\sum_{i=1}^n (y_i-\alpha)^2 + \half \tr\left((\E[\xi^2]\bH^2 + \bI_n)\btU \right) - \E[\xi](\by-\balpha)^\top\bH\E[\bu] \right)   + \const \\  
\end{align*}

This is a gamma distribution with shape $s = n+1$ and rate $r = \half\sum_{i=1}^n (y_i-\alpha)^2 + \half \tr\left((\E[\xi^2]\bH^2 + \bI_n)\btU \right) - \E[\xi](\by-\balpha)^\top\bH\E[\bu]$. The mean is $s / r$, and the mean of $\log \psi$ is $\Psi(s) - \log r$, where $\Psi$ is the digamma function.

\subsection{Monitoring the lower bound}

A convergence criterion would be when there is no more significant increase in the lower bound $\cL$, as defined by
\begin{align*}
  \cL &= \int q(\bu,\xi,\psi) \log \left[ \frac{p(\by,\bu,\xi,\psi)}{q(\bu,\xi,\psi)} \right]  \d\bu \d\xi \d\psi \\[1pt]
  &= \E[\log p(\by,\bu,\xi,\psi)] - \E[\log q(\bu,\xi,\psi)] \\
  &= \E\left[ \log p(\by | \bfeta) \right]
  + \E\left[ \log p(\bu) \right] 
  + \cancel{\E\left[ \log p(\xi) \right]}
  + \cancel{\E\left[ \log p(\psi) \right]}  \\
  &\phantom{==} - \E\left[ \log q(\bu) \right]
  - \E\left[ \log q(\xi) \right]
  - \E\left[ \log q(\psi) \right]
\end{align*}

\begin{defn}[Differential entropy]
  The differential entropy $\cH$ of a pdf $p(x)$ is given by
  \[
    \cH(p) = -\int p(x) \log p(x) \d x = -\E_p[\log p(x)].
  \]
\end{defn}

\begin{lem}\label{thm:normentropy}
  Let $p(x)$ be the pdf of a random variable $x$. Then if
  \begin{enumerate}[label=(\roman*)]
    \item $p$ is a univariate normal distribution with mean $\mu$ and variance $\psi^{-1}$,
    \[
      \cH(p) = \half (1 + \log 2\pi) - \half \log \psi
    \]
    \item $p$ is a $d$-dimensional normal distribution with mean $\mu$ and variance $\Sigma$,
    \[
      \cH(p) = \half[d] (1 + \log 2\pi) + \half \log \vert \Sigma \vert 
    \]
    \item $p$ is the pdf of a gamma distribution with shape $s$ and rate $r$,
    \[
      \cH(p) = s - \log r + \log \Gamma(s) + (1-s)\Psi(s)
    \]
    where $\Psi(s) = \d\log\Gamma(s) / \d s = \Gamma'(s) / \Gamma(s)$ is the digamma function.
  \end{enumerate}
\end{lem}

\subsubsection{Terms involving distributions of $\bu$}

\begin{align*}
  \E\left[ \log p(\by|\bfeta) \right] + \E\left[ \log p(\bu) \right] - \E\left[ \log q(\bu) \right]   &= \E \left[ -\half[n] \log 2\pi +\half[n] \log \psi - \half[\psi] \Vert \by - \balpha - \xi \bH \bu \Vert^2\right] \\
  &\phantom{==}+ \E\left[ -\half[n] \log 2\pi + \half[n] \log \psi - \half[\psi] \Vert \bu \Vert^2 \right] + \cH(q(\bu)) \\
  &= \cancel{-\half[n] \log 2\pi} + \half[n] \E[\log \psi] - \half[\E\psi] \E\left[ \Vert \by - \balpha - \xi \bH \bu \Vert^2\right]  \\
  &\phantom{==} -\half[n] \log 2\pi + \half[n]\E [\log \psi] - \half[\E\psi] \E[\Vert\bu\Vert^2] \\
  &\phantom{==} + \half[n] (1 + \cancel{\log 2\pi}) - \half \log \vert \bA  \vert - \half[n]\log \E\psi  \\
  &= \half[n] \left(1 + 2\E[\log \psi] - \log \E\psi - \log 2\pi \right) - r\E\psi - \half \log \vert \bA  \vert \\
  &= \half[n] \left(1 + 2(\Psi(s) - \log r) - \log (s/r) - \log 2\pi \right) - r(s/r) - \half \log \vert \bA  \vert \\
  &= \half[n] \left(1 + 2\Psi(n+1) - \log r - \log (n+1) - \log 2\pi \right)  - \half \log \vert \bA  \vert - (n+1)
\end{align*}

\subsubsection{Terms involving distribution of $q(\xi)$}

\begin{align*}
  -\E\left[ \log q(\xi) \right] &= \cH\big(q(\xi)\big) \\
  &= \half (1 + \log 2\pi) - \half \log \tr\left(\bH^2\btU \right) - \half \log \E[\psi]
\end{align*}

\subsubsection{Terms involving distribution of $q(\psi)$}

\begin{align*}
  -\E\left[ \log q(\alpha) \right] &= \cH\big(q(\psi)\big) \\
  &= (n + 1) - \log r + \log \Gamma(n+1) - n\Psi(n+1)
\end{align*}

\newpage
\subsection{The variational Bayes EM algorithm}

\algrenewcommand{\algorithmiccomment}[1]{{\color{gray}\hskip2em$\triangleright$ #1}}
\begin{algorithm}[H]
\caption{VB-EM algorithm for the probit I-prior model}\label{alg:VBEM}
\begin{algorithmic}[1]
\Procedure{Initialise}{}
  \State $\hat\alpha \gets \sum_{i=1}^n y_i / n$
  \State $\tilde\xi^{(0)} \gets 1$
  \State $\tilde\xi^{sq(0)} \gets 1$ \Comment{this is $\E[\xi^2]$}
  \State $\tilde\psi^{(0)} \gets 1$
  \State $\tilde\bu^{(0)} \gets \bzero_n$ \Comment{or draw $u_i^{(0)} \ \sim \N(0,1)$ for $i=1,\dots,n$.}
\EndProcedure
\Statex
\Procedure{Update for $\bu$ }{time $t$}
  \State $\bA \gets \tilde\xi^{sq(t)}\bH^2 + \bI_n$
  \State $\ba \gets \tilde\xi^{(t)}\bH(\by - \hat\balpha)$
  \State $\tilde\bu^{(t+1)} \gets \bA^{-1}\ba$
  \State $\btU^{(t+1)} \gets \bA^{-1}\big((1/\tilde\psi^{(t)})\bI_n + \ba\ba^\top\bA^{-1}\big)$
  \State $\text{logdetA}^{(t+1)} \gets \log \vert \bA \vert$
\EndProcedure
\Statex
\Procedure{Update for $\xi$ }{time $t$}
  \State $c \gets c^{(t+1)} \gets \tr\left(\bH^2\btU^{(t+1)}\right)$
  \State $d \gets (\by - \hat\balpha)^\top\bH\tilde\bu^{(t+1)}$
  \State $\tilde\xi^{(t+1)} \gets d / c$
  \State $\tilde\xi^{sq(t+1)} \gets 1 / (\tilde\psi^{(t)}c) + (d / c)^2$
\EndProcedure
\Statex
\Procedure{Update for $\psi$ }{time $t$}
  \State $r \gets r^{(t+1)} \gets \half\sum_{i=1}^n (y_i- \hat\alpha)^2 +  \half\tr\left((\tilde\xi^{sq(t+1)}\bH^2 + \bI_n)\btU^{(t+1)} \right) - \tilde\xi^{(t+1)}(\by - \hat\balpha)^\top\bH\tilde\bu^{(t+1)} $
  \State $\tilde\psi^{(t+1)} \gets (n+1)/r$
\EndProcedure	
\Statex
\Procedure{Calculate lower bound }{time $t$}
  \State $\cL^{(t)} \gets \half[n+1] \left(1  - \log r^{(t+1)} - \log (n+1) \right) -  \half[n-1] \log 2\pi  + \log \Gamma(n+1) - \phantom{++++} \half \left( \text{logdetA}^{(t+1)}  + \log c^{(t+1)}  \right) 
$
\EndProcedure	
\Statex
\Procedure{The VB-EM algorithm}{}
  \State $t \gets 0$
  \While{$\cL^{(t+1)} - \cL^{(t)} > \delta$ \textbf{or} $t < t_{max}$}{}
    \State \textbf{call} \Call{Update for $\bu$}{}
    \State \textbf{call} \Call{Update for $\xi$}{}
    \State \textbf{call} \Call{Update for $\psi$}{}
    \State \textbf{call} \Call{Calculate lower bound}{}
    \State $t \gets t + 1$
  \EndWhile
\EndProcedure
\algstore{VBEMbreak}	
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\begin{algorithmic}[1]
\algrestore{VBEMbreak}	
\State \Return $(\hat\bw, \hat\alpha, \hat\lambda, \hat\psi) \gets (\tilde\bu^{(t)} / \tilde\psi^{2(t)}, \hat\alpha, \tilde\xi^{(t)} / \tilde\psi^{2(t)}, \tilde\psi^{-2(t)}) \vspace{1mm}$ \Comment{converged parameter estimates}
\State \Return $(\hat y_1, \dots, \hat y_n) \gets \hat\alpha\bone + \hat\lambda \bH \hat\bw  $ \Comment{fitted values}
\end{algorithmic}
\end{algorithm}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% REFERENCES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\ifstandalone
%\nocite{*}
%\bibliographystyle{apalike}
%\bibliography{haziq}
%\fi
\end{document}















