\documentclass[a4paper,showframe,11pt]{report}
\usepackage{standalone}
\standalonetrue
\ifstandalone
  \usepackage{../../haziq_thesis}
  \usepackage{../../haziq_maths}
  \usepackage{../../haziq_glossary}
  \addbibresource{../../bib/haziq.bib}
  \externaldocument{../01/.texpadtmp/introduction}
\fi

<<setup, include = FALSE, cache = FALSE>>=
# Load external .R file
knitr::read_chunk("00-prelim.R")
knitr::read_chunk("04-01-multilevel.R")
@
<<prelim, include = FALSE>>=
@

\begin{document}

In this section, a comparison between a standard random effects model and the I-prior approach for estimating varying intercept and varying slopes model is illustrated. We consider a data set which accompanies the MLwiN software on the academic achievements of 4,059 pupils at 65 inner-London schools citep{rasbash2012user, R2MLwiN}. The response variable of interest are the pupils' (normalised) GCSE scores at age 16 encoded in the variable \code{normexam}. Also available in the data set is a pupil-specific regressor, which is the London reading test results (\code{standlrt}) for each pupil taken when they were aged 11.

<<04_01_data>>=
@
<<04_01_analysis, include = FALSE, cache = TRUE, cache.lazy = FALSE>>=
@

First, we consider the varying intercept model. A standard approach to fitting this model is the random intercept model, which is based on the assumption that the intercepts are iid normal with zero mean. In \proglang{R}, packages such as \pkg{lme4} are able to fit these types of models. In the I-prior approach, the response variable \code{normexam} is regressed against the covariate \code{school} indicating the school that pupil had attended, which is assumed to have a nominal effect on GCSE scores. In other words, the regression function lies in the Pearson RKHS. As the variable \code{school} is a factor-type variable, the \pkg{iprior} package knows to treat this variable with the Pearson kernel automatically without user specification.

<<eval = FALSE>>=
# Model 1: Varying intercept model
(mod1.fit <- iprior(normexam ~ school, data = tutorial))
@
\vspace{-0.5em}{\setlength\parindent{0pt}(output omitted)}
<<echo = FALSE>>=
cat(paste0(mod1.output, "\n", collapse = ""))
@

In Figure \ref{fig:plot}(a), the posterior means of the intercepts are plotted for the random effects model and the I-prior model. It can be seen that the estimates are in broad agreement, with conspicuously different estimates for schools 48 (\Sexpr{int1a} vs. \Sexpr{int1}) and 54 (\Sexpr{int2a} vs. \Sexpr{int2}), the I-prior giving the larger estimate in absolute values in both cases. The reason for this is that the I-prior variance for each school's regression function in a Pearson RKHS is inversely proportional to the sample size for that school. A proof of this is given in Appendix \ref{apx:pears}. Indeed, schools 48 and 54 have the smallest sample sizes of all schools, namely 2 and 8 respectively, whilst the next smallest is school 37 with 22 students.

<<04_01_plot_em, echo = FALSE, fig.height = 4, fig.width = 4, out.width = "7.1cm", out.height = "7.1cm", fig.show = "hold", fig.cap = "Estimated intercepts and slopes for school achievement data under (a) varying intercept (left); and (b) varying slope model. The numbers plotted are the school indices with the identity line for reference.">>=
@

Next we consider the varying slope model which regresses, for each school, the GCSE score on the results of the London reading test taken at age 11 (\code{standlrt}). A standard approach to fitting this model is the random intercept/slopes model, which is based on the assumption that the intercept/slope pairs are iid bivariate normal with zero means. To obtain an I-prior, we assume as above a nominal effect of school, and a linear effect of \code{standlrt} (using the canonical kernel on this variable). An interaction between the variables \code{standlrt} and \code{school} imply that the effect of the covariate \code{standlrt} varies with each school.

<<eval = FALSE>>=
# Model 2: Varying slope model
(mod2.fit <- iprior(normexam ~ school * standlrt, data = tutorial))
@
\vspace{-0.5em}{\setlength\parindent{0pt}(output omitted)}
<<echo = FALSE>>=
cat(paste0(mod2.output, "\n", collapse = ""))
@

In Figure \ref{fig:plot}(b), the posterior means of the slopes obtained using the standard random effects model are plotted against the ones obtained using the I-prior. Again, we see broad agreement of the estimates, but much less so than the varying intercept model.

A limited cross-validation study yielded on average a small advantage of the standard random effects approach in terms of mean squared error, in the order of half a percent, indicating the iid assumption in the random effects models is reasonable. However, an advantage of the I-prior is that no a priori assumption about the distribution of the parameters need to be made. Furthermore, our approach is more parsimonious and allows potentially simpler estimation and testing.

\end{document}

<<>>=
move_files_to_chapter()
@
